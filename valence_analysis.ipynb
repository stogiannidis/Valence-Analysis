{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "558f68ec",
   "metadata": {},
   "source": [
    "# Dissecting Spotify Valence\n",
    "\n",
    "---\n",
    "\n",
    ">Stogiannidis Ilias Marios  <br />\n",
    ">Department of Informatics  <br />\n",
    ">Athens University of Economics and Business  <br />\n",
    ">stoyianel@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795d9ecb",
   "metadata": {},
   "source": [
    "### Extracting data from a spotify playlist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "d891f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84702e1d",
   "metadata": {},
   "source": [
    "### Setting up the Spotify API*\n",
    "\n",
    "For storing our credentials, we'll create a file spotify_config.py with the following contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'client_id' : 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX',\n",
    "    'client_secret' :'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "f42e9301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotify_config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "06b76157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authentication - without user\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=config[\"cid\"], client_secret=config[\"csecret\"])\n",
    "sp = spotipy.Spotify(client_credentials_manager = client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "84946e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_creator = \"Susanna Ketola\"\n",
    "playlist_id = \"4rnleEAOdmFAbRcNCgZMpY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc593b32",
   "metadata": {},
   "source": [
    "* We are using the function below to extract the data from the spotify api and storing it to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "e79e615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_features_list = [\"artist\", \"album\", \"track_name\", \"track_id\",\"acousticness\",\n",
    "                             \"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\",\n",
    "                             \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_ms\", \"time_signature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "430d525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_playlist(creator, playlist_id):\n",
    "    \n",
    "    # Create empty dataframe\n",
    "    playlist_features_list = [\"artist\", \"album\", \"track_name\", \"track_id\",\"acousticness\",\n",
    "                             \"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\",\n",
    "                             \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_ms\", \"time_signature\"]\n",
    "    playlist_df = pd.DataFrame(columns = playlist_features_list)\n",
    "    \n",
    "    # Create empty dict\n",
    "    playlist_features = {}\n",
    "    \n",
    "    # Loop through every track in the playlist, extract features and append the features to the playlist df\n",
    "    results = sp.user_playlist_tracks(creator,playlist_id)\n",
    "    tracks = results['items']\n",
    "    while results['next']:\n",
    "        results = sp.next(results)\n",
    "        tracks.extend(results['items'])\n",
    "    for track in tracks:\n",
    "        # Get metadata\n",
    "        playlist_features[\"artist\"] = track[\"track\"][\"album\"][\"artists\"][0][\"name\"]\n",
    "        playlist_features[\"album\"] = track[\"track\"][\"album\"][\"name\"]\n",
    "        playlist_features[\"track_name\"] = track[\"track\"][\"name\"]\n",
    "        playlist_features[\"track_id\"] = track[\"track\"][\"id\"]\n",
    "        # Get audio features\n",
    "        audio_features = sp.audio_features(playlist_features[\"track_id\"])[0]\n",
    "        for feature in playlist_features_list[4:]:\n",
    "            playlist_features[feature] = audio_features[feature]\n",
    "        \n",
    "        # Concat the dfs\n",
    "        track_df = pd.DataFrame(playlist_features, index = [0])\n",
    "        playlist_df = pd.concat([playlist_df, track_df], ignore_index = True)\n",
    "        \n",
    "    return playlist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the code in comments below is used to store the dataframe to a csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "1b40cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#playlist_df = analyze_playlist(playlist_creator,playlist_id)\n",
    "#playlist_df.to_csv('playlist_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "e8a5865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_df = pd.read_csv(\"playlist_features.csv\")\n",
    "playlist_df.drop(columns = [\"Unnamed: 0\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "f859db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_df = playlist_df.astype({'acousticness': 'float64','danceability': 'float64', 'energy': 'float64', 'key': 'float64', 'loudness': 'float64', 'mode': 'float64', 'speechiness': 'float64', 'instrumentalness': 'float64', 'liveness': 'float64', 'valence': 'float64', 'tempo': 'float64', 'duration_ms': 'float64', 'time_signature': 'float64'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ce46fd",
   "metadata": {},
   "source": [
    "### Q1: Expore which Features Influence Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "4dceec66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c5b00_row0_col0, #T_c5b00_row1_col1, #T_c5b00_row2_col2, #T_c5b00_row3_col3, #T_c5b00_row4_col4, #T_c5b00_row5_col5, #T_c5b00_row6_col6, #T_c5b00_row7_col7, #T_c5b00_row8_col8, #T_c5b00_row9_col9, #T_c5b00_row10_col10, #T_c5b00_row11_col11, #T_c5b00_row12_col12 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row0_col1 {\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row0_col2, #T_c5b00_row0_col4, #T_c5b00_row0_col8, #T_c5b00_row0_col9, #T_c5b00_row0_col12, #T_c5b00_row1_col10, #T_c5b00_row1_col11, #T_c5b00_row2_col0, #T_c5b00_row3_col5, #T_c5b00_row5_col3, #T_c5b00_row6_col7, #T_c5b00_row9_col7, #T_c5b00_row11_col1, #T_c5b00_row11_col6 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row0_col3, #T_c5b00_row3_col6, #T_c5b00_row5_col1 {\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row0_col5, #T_c5b00_row3_col11 {\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row0_col6, #T_c5b00_row2_col3, #T_c5b00_row9_col6, #T_c5b00_row10_col5 {\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row0_col7, #T_c5b00_row7_col12, #T_c5b00_row11_col9 {\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row0_col10 {\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row0_col11, #T_c5b00_row4_col5, #T_c5b00_row7_col5, #T_c5b00_row11_col5 {\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row1_col0, #T_c5b00_row12_col1 {\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row1_col2, #T_c5b00_row7_col0 {\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row1_col3, #T_c5b00_row4_col3, #T_c5b00_row6_col5, #T_c5b00_row12_col10 {\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row1_col4 {\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row1_col5, #T_c5b00_row2_col5, #T_c5b00_row3_col8, #T_c5b00_row5_col9, #T_c5b00_row9_col5 {\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row1_col6 {\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row1_col7, #T_c5b00_row6_col11, #T_c5b00_row10_col1 {\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row1_col8, #T_c5b00_row4_col6 {\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row1_col9 {\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row1_col12, #T_c5b00_row12_col9 {\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row2_col1, #T_c5b00_row7_col3, #T_c5b00_row8_col3, #T_c5b00_row9_col12, #T_c5b00_row12_col6 {\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row2_col4 {\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row2_col6 {\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row2_col7, #T_c5b00_row3_col10, #T_c5b00_row11_col3, #T_c5b00_row12_col3 {\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row2_col8 {\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row2_col9, #T_c5b00_row9_col4 {\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row2_col10, #T_c5b00_row9_col0 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row2_col11 {\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row2_col12, #T_c5b00_row3_col1, #T_c5b00_row7_col1, #T_c5b00_row8_col9 {\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row3_col0 {\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row3_col2 {\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row3_col4, #T_c5b00_row12_col0 {\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row3_col7, #T_c5b00_row7_col6, #T_c5b00_row9_col11 {\n",
       "  background-color: #4f69d9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row3_col9, #T_c5b00_row7_col10, #T_c5b00_row9_col3, #T_c5b00_row10_col9, #T_c5b00_row10_col11 {\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row3_col12 {\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row4_col0 {\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row4_col1 {\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row4_col2 {\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row4_col7 {\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row4_col8, #T_c5b00_row4_col10, #T_c5b00_row8_col6 {\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row4_col9 {\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row4_col11, #T_c5b00_row12_col11 {\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row4_col12, #T_c5b00_row5_col10 {\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row5_col0 {\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row5_col2, #T_c5b00_row12_col4 {\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row5_col4, #T_c5b00_row8_col0 {\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row5_col6, #T_c5b00_row6_col12, #T_c5b00_row8_col5, #T_c5b00_row10_col8, #T_c5b00_row11_col8, #T_c5b00_row11_col10, #T_c5b00_row11_col12, #T_c5b00_row12_col5 {\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row5_col7 {\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row5_col8 {\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row5_col11, #T_c5b00_row6_col3, #T_c5b00_row6_col8, #T_c5b00_row6_col9 {\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row5_col12, #T_c5b00_row11_col7 {\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row6_col0, #T_c5b00_row8_col4 {\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row6_col1 {\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row6_col2 {\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row6_col4, #T_c5b00_row6_col10 {\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row7_col2, #T_c5b00_row12_col2 {\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row7_col4 {\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row7_col8, #T_c5b00_row8_col1 {\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row7_col9 {\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row7_col11 {\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row8_col2 {\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row8_col7 {\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row8_col10, #T_c5b00_row9_col10, #T_c5b00_row10_col3 {\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row8_col11 {\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row8_col12 {\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row9_col1 {\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row9_col2 {\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row9_col8 {\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row10_col0 {\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row10_col2 {\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row10_col4 {\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row10_col6 {\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row10_col7 {\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row10_col12 {\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row11_col0, #T_c5b00_row11_col4 {\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row11_col2 {\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c5b00_row12_col7 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c5b00_row12_col8 {\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c5b00_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >acousticness</th>\n",
       "      <th class=\"col_heading level0 col1\" >danceability</th>\n",
       "      <th class=\"col_heading level0 col2\" >energy</th>\n",
       "      <th class=\"col_heading level0 col3\" >key</th>\n",
       "      <th class=\"col_heading level0 col4\" >loudness</th>\n",
       "      <th class=\"col_heading level0 col5\" >mode</th>\n",
       "      <th class=\"col_heading level0 col6\" >speechiness</th>\n",
       "      <th class=\"col_heading level0 col7\" >instrumentalness</th>\n",
       "      <th class=\"col_heading level0 col8\" >liveness</th>\n",
       "      <th class=\"col_heading level0 col9\" >valence</th>\n",
       "      <th class=\"col_heading level0 col10\" >tempo</th>\n",
       "      <th class=\"col_heading level0 col11\" >duration_ms</th>\n",
       "      <th class=\"col_heading level0 col12\" >time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c5b00_level0_row0\" class=\"row_heading level0 row0\" >acousticness</th>\n",
       "      <td id=\"T_c5b00_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_c5b00_row0_col1\" class=\"data row0 col1\" >-0.128429</td>\n",
       "      <td id=\"T_c5b00_row0_col2\" class=\"data row0 col2\" >-0.525334</td>\n",
       "      <td id=\"T_c5b00_row0_col3\" class=\"data row0 col3\" >-0.000160</td>\n",
       "      <td id=\"T_c5b00_row0_col4\" class=\"data row0 col4\" >-0.409016</td>\n",
       "      <td id=\"T_c5b00_row0_col5\" class=\"data row0 col5\" >0.031570</td>\n",
       "      <td id=\"T_c5b00_row0_col6\" class=\"data row0 col6\" >0.021099</td>\n",
       "      <td id=\"T_c5b00_row0_col7\" class=\"data row0 col7\" >-0.017128</td>\n",
       "      <td id=\"T_c5b00_row0_col8\" class=\"data row0 col8\" >-0.099146</td>\n",
       "      <td id=\"T_c5b00_row0_col9\" class=\"data row0 col9\" >-0.152342</td>\n",
       "      <td id=\"T_c5b00_row0_col10\" class=\"data row0 col10\" >-0.120919</td>\n",
       "      <td id=\"T_c5b00_row0_col11\" class=\"data row0 col11\" >-0.053462</td>\n",
       "      <td id=\"T_c5b00_row0_col12\" class=\"data row0 col12\" >-0.090135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5b00_level0_row1\" class=\"row_heading level0 row1\" >danceability</th>\n",
       "      <td id=\"T_c5b00_row1_col0\" class=\"data row1 col0\" >-0.128429</td>\n",
       "      <td id=\"T_c5b00_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_c5b00_row1_col2\" class=\"data row1 col2\" >-0.017655</td>\n",
       "      <td id=\"T_c5b00_row1_col3\" class=\"data row1 col3\" >-0.005442</td>\n",
       "      <td id=\"T_c5b00_row1_col4\" class=\"data row1 col4\" >0.009181</td>\n",
       "      <td id=\"T_c5b00_row1_col5\" class=\"data row1 col5\" >-0.032772</td>\n",
       "      <td id=\"T_c5b00_row1_col6\" class=\"data row1 col6\" >0.188258</td>\n",
       "      <td id=\"T_c5b00_row1_col7\" class=\"data row1 col7\" >-0.004625</td>\n",
       "      <td id=\"T_c5b00_row1_col8\" class=\"data row1 col8\" >-0.076984</td>\n",
       "      <td id=\"T_c5b00_row1_col9\" class=\"data row1 col9\" >0.374874</td>\n",
       "      <td id=\"T_c5b00_row1_col10\" class=\"data row1 col10\" >-0.137144</td>\n",
       "      <td id=\"T_c5b00_row1_col11\" class=\"data row1 col11\" >-0.193455</td>\n",
       "      <td id=\"T_c5b00_row1_col12\" class=\"data row1 col12\" >0.114482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5b00_level0_row2\" class=\"row_heading level0 row2\" >energy</th>\n",
       "      <td id=\"T_c5b00_row2_col0\" class=\"data row2 col0\" >-0.525334</td>\n",
       "      <td id=\"T_c5b00_row2_col1\" class=\"data row2 col1\" >-0.017655</td>\n",
       "      <td id=\"T_c5b00_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_c5b00_row2_col3\" class=\"data row2 col3\" >0.006415</td>\n",
       "      <td id=\"T_c5b00_row2_col4\" class=\"data row2 col4\" >0.689456</td>\n",
       "      <td id=\"T_c5b00_row2_col5\" class=\"data row2 col5\" >-0.035810</td>\n",
       "      <td id=\"T_c5b00_row2_col6\" class=\"data row2 col6\" >-0.081145</td>\n",
       "      <td id=\"T_c5b00_row2_col7\" class=\"data row2 col7\" >0.081076</td>\n",
       "      <td id=\"T_c5b00_row2_col8\" class=\"data row2 col8\" >0.166090</td>\n",
       "      <td id=\"T_c5b00_row2_col9\" class=\"data row2 col9\" >0.354886</td>\n",
       "      <td id=\"T_c5b00_row2_col10\" class=\"data row2 col10\" >0.141599</td>\n",
       "      <td id=\"T_c5b00_row2_col11\" class=\"data row2 col11\" >0.058517</td>\n",
       "      <td id=\"T_c5b00_row2_col12\" class=\"data row2 col12\" >0.082322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5b00_level0_row3\" class=\"row_heading level0 row3\" >key</th>\n",
       "      <td id=\"T_c5b00_row3_col0\" class=\"data row3 col0\" >-0.000160</td>\n",
       "      <td id=\"T_c5b00_row3_col1\" class=\"data row3 col1\" >-0.005442</td>\n",
       "      <td id=\"T_c5b00_row3_col2\" class=\"data row3 col2\" >0.006415</td>\n",
       "      <td id=\"T_c5b00_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_c5b00_row3_col4\" class=\"data row3 col4\" >-0.006232</td>\n",
       "      <td id=\"T_c5b00_row3_col5\" class=\"data row3 col5\" >-0.153581</td>\n",
       "      <td id=\"T_c5b00_row3_col6\" class=\"data row3 col6\" >0.019253</td>\n",
       "      <td id=\"T_c5b00_row3_col7\" class=\"data row3 col7\" >0.016174</td>\n",
       "      <td id=\"T_c5b00_row3_col8\" class=\"data row3 col8\" >0.015445</td>\n",
       "      <td id=\"T_c5b00_row3_col9\" class=\"data row3 col9\" >0.024043</td>\n",
       "      <td id=\"T_c5b00_row3_col10\" class=\"data row3 col10\" >0.012406</td>\n",
       "      <td id=\"T_c5b00_row3_col11\" class=\"data row3 col11\" >-0.001163</td>\n",
       "      <td id=\"T_c5b00_row3_col12\" class=\"data row3 col12\" >-0.004152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5b00_level0_row4\" class=\"row_heading level0 row4\" >loudness</th>\n",
       "      <td id=\"T_c5b00_row4_col0\" class=\"data row4 col0\" >-0.409016</td>\n",
       "      <td id=\"T_c5b00_row4_col1\" class=\"data row4 col1\" >0.009181</td>\n",
       "      <td id=\"T_c5b00_row4_col2\" class=\"data row4 col2\" >0.689456</td>\n",
       "      <td id=\"T_c5b00_row4_col3\" class=\"data row4 col3\" >-0.006232</td>\n",
       "      <td id=\"T_c5b00_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_c5b00_row4_col5\" class=\"data row4 col5\" >-0.014824</td>\n",
       "      <td id=\"T_c5b00_row4_col6\" class=\"data row4 col6\" >-0.112025</td>\n",
       "      <td id=\"T_c5b00_row4_col7\" class=\"data row4 col7\" >-0.051910</td>\n",
       "      <td id=\"T_c5b00_row4_col8\" class=\"data row4 col8\" >0.096353</td>\n",
       "      <td id=\"T_c5b00_row4_col9\" class=\"data row4 col9\" >0.208928</td>\n",
       "      <td id=\"T_c5b00_row4_col10\" class=\"data row4 col10\" >0.066475</td>\n",
       "      <td id=\"T_c5b00_row4_col11\" class=\"data row4 col11\" >0.027564</td>\n",
       "      <td id=\"T_c5b00_row4_col12\" class=\"data row4 col12\" >0.044661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5b00_level0_row5\" class=\"row_heading level0 row5\" >mode</th>\n",
       "      <td id=\"T_c5b00_row5_col0\" class=\"data row5 col0\" >0.031570</td>\n",
       "      <td id=\"T_c5b00_row5_col1\" class=\"data row5 col1\" >-0.032772</td>\n",
       "      <td id=\"T_c5b00_row5_col2\" class=\"data row5 col2\" >-0.035810</td>\n",
       "      <td id=\"T_c5b00_row5_col3\" class=\"data row5 col3\" >-0.153581</td>\n",
       "      <td id=\"T_c5b00_row5_col4\" class=\"data row5 col4\" >-0.014824</td>\n",
       "      <td id=\"T_c5b00_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "      <td id=\"T_c5b00_row5_col6\" class=\"data row5 col6\" >-0.007684</td>\n",
       "      <td id=\"T_c5b00_row5_col7\" class=\"data row5 col7\" >-0.014467</td>\n",
       "      <td id=\"T_c5b00_row5_col8\" class=\"data row5 col8\" >-0.026455</td>\n",
       "      <td id=\"T_c5b00_row5_col9\" class=\"data row5 col9\" >-0.033520</td>\n",
       "      <td id=\"T_c5b00_row5_col10\" class=\"data row5 col10\" >0.004752</td>\n",
       "      <td id=\"T_c5b00_row5_col11\" class=\"data row5 col11\" >-0.014321</td>\n",
       "      <td id=\"T_c5b00_row5_col12\" class=\"data row5 col12\" >-0.027352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5b00_level0_row6\" class=\"row_heading level0 row6\" >speechiness</th>\n",
       "      <td id=\"T_c5b00_row6_col0\" class=\"data row6 col0\" >0.021099</td>\n",
       "      <td id=\"T_c5b00_row6_col1\" class=\"data row6 col1\" >0.188258</td>\n",
       "      <td id=\"T_c5b00_row6_col2\" class=\"data row6 col2\" >-0.081145</td>\n",
       "      <td id=\"T_c5b00_row6_col3\" class=\"data row6 col3\" >0.019253</td>\n",
       "      <td id=\"T_c5b00_row6_col4\" class=\"data row6 col4\" >-0.112025</td>\n",
       "      <td id=\"T_c5b00_row6_col5\" class=\"data row6 col5\" >-0.007684</td>\n",
       "      <td id=\"T_c5b00_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "      <td id=\"T_c5b00_row6_col7\" class=\"data row6 col7\" >-0.057842</td>\n",
       "      <td id=\"T_c5b00_row6_col8\" class=\"data row6 col8\" >0.067565</td>\n",
       "      <td id=\"T_c5b00_row6_col9\" class=\"data row6 col9\" >0.021094</td>\n",
       "      <td id=\"T_c5b00_row6_col10\" class=\"data row6 col10\" >0.098401</td>\n",
       "      <td id=\"T_c5b00_row6_col11\" class=\"data row6 col11\" >-0.134268</td>\n",
       "      <td id=\"T_c5b00_row6_col12\" class=\"data row6 col12\" >0.032836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5b00_level0_row7\" class=\"row_heading level0 row7\" >instrumentalness</th>\n",
       "      <td id=\"T_c5b00_row7_col0\" class=\"data row7 col0\" >-0.017128</td>\n",
       "      <td id=\"T_c5b00_row7_col1\" class=\"data row7 col1\" >-0.004625</td>\n",
       "      <td id=\"T_c5b00_row7_col2\" class=\"data row7 col2\" >0.081076</td>\n",
       "      <td id=\"T_c5b00_row7_col3\" class=\"data row7 col3\" >0.016174</td>\n",
       "      <td id=\"T_c5b00_row7_col4\" class=\"data row7 col4\" >-0.051910</td>\n",
       "      <td id=\"T_c5b00_row7_col5\" class=\"data row7 col5\" >-0.014467</td>\n",
       "      <td id=\"T_c5b00_row7_col6\" class=\"data row7 col6\" >-0.057842</td>\n",
       "      <td id=\"T_c5b00_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "      <td id=\"T_c5b00_row7_col8\" class=\"data row7 col8\" >0.004481</td>\n",
       "      <td id=\"T_c5b00_row7_col9\" class=\"data row7 col9\" >-0.053718</td>\n",
       "      <td id=\"T_c5b00_row7_col10\" class=\"data row7 col10\" >0.037712</td>\n",
       "      <td id=\"T_c5b00_row7_col11\" class=\"data row7 col11\" >0.003018</td>\n",
       "      <td id=\"T_c5b00_row7_col12\" class=\"data row7 col12\" >-0.049221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5b00_level0_row8\" class=\"row_heading level0 row8\" >liveness</th>\n",
       "      <td id=\"T_c5b00_row8_col0\" class=\"data row8 col0\" >-0.099146</td>\n",
       "      <td id=\"T_c5b00_row8_col1\" class=\"data row8 col1\" >-0.076984</td>\n",
       "      <td id=\"T_c5b00_row8_col2\" class=\"data row8 col2\" >0.166090</td>\n",
       "      <td id=\"T_c5b00_row8_col3\" class=\"data row8 col3\" >0.015445</td>\n",
       "      <td id=\"T_c5b00_row8_col4\" class=\"data row8 col4\" >0.096353</td>\n",
       "      <td id=\"T_c5b00_row8_col5\" class=\"data row8 col5\" >-0.026455</td>\n",
       "      <td id=\"T_c5b00_row8_col6\" class=\"data row8 col6\" >0.067565</td>\n",
       "      <td id=\"T_c5b00_row8_col7\" class=\"data row8 col7\" >0.004481</td>\n",
       "      <td id=\"T_c5b00_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
       "      <td id=\"T_c5b00_row8_col9\" class=\"data row8 col9\" >0.028190</td>\n",
       "      <td id=\"T_c5b00_row8_col10\" class=\"data row8 col10\" >0.024986</td>\n",
       "      <td id=\"T_c5b00_row8_col11\" class=\"data row8 col11\" >0.025322</td>\n",
       "      <td id=\"T_c5b00_row8_col12\" class=\"data row8 col12\" >0.017061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5b00_level0_row9\" class=\"row_heading level0 row9\" >valence</th>\n",
       "      <td id=\"T_c5b00_row9_col0\" class=\"data row9 col0\" >-0.152342</td>\n",
       "      <td id=\"T_c5b00_row9_col1\" class=\"data row9 col1\" >0.374874</td>\n",
       "      <td id=\"T_c5b00_row9_col2\" class=\"data row9 col2\" >0.354886</td>\n",
       "      <td id=\"T_c5b00_row9_col3\" class=\"data row9 col3\" >0.024043</td>\n",
       "      <td id=\"T_c5b00_row9_col4\" class=\"data row9 col4\" >0.208928</td>\n",
       "      <td id=\"T_c5b00_row9_col5\" class=\"data row9 col5\" >-0.033520</td>\n",
       "      <td id=\"T_c5b00_row9_col6\" class=\"data row9 col6\" >0.021094</td>\n",
       "      <td id=\"T_c5b00_row9_col7\" class=\"data row9 col7\" >-0.053718</td>\n",
       "      <td id=\"T_c5b00_row9_col8\" class=\"data row9 col8\" >0.028190</td>\n",
       "      <td id=\"T_c5b00_row9_col9\" class=\"data row9 col9\" >1.000000</td>\n",
       "      <td id=\"T_c5b00_row9_col10\" class=\"data row9 col10\" >0.026833</td>\n",
       "      <td id=\"T_c5b00_row9_col11\" class=\"data row9 col11\" >-0.110459</td>\n",
       "      <td id=\"T_c5b00_row9_col12\" class=\"data row9 col12\" >0.067634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5b00_level0_row10\" class=\"row_heading level0 row10\" >tempo</th>\n",
       "      <td id=\"T_c5b00_row10_col0\" class=\"data row10 col0\" >-0.120919</td>\n",
       "      <td id=\"T_c5b00_row10_col1\" class=\"data row10 col1\" >-0.137144</td>\n",
       "      <td id=\"T_c5b00_row10_col2\" class=\"data row10 col2\" >0.141599</td>\n",
       "      <td id=\"T_c5b00_row10_col3\" class=\"data row10 col3\" >0.012406</td>\n",
       "      <td id=\"T_c5b00_row10_col4\" class=\"data row10 col4\" >0.066475</td>\n",
       "      <td id=\"T_c5b00_row10_col5\" class=\"data row10 col5\" >0.004752</td>\n",
       "      <td id=\"T_c5b00_row10_col6\" class=\"data row10 col6\" >0.098401</td>\n",
       "      <td id=\"T_c5b00_row10_col7\" class=\"data row10 col7\" >0.037712</td>\n",
       "      <td id=\"T_c5b00_row10_col8\" class=\"data row10 col8\" >0.024986</td>\n",
       "      <td id=\"T_c5b00_row10_col9\" class=\"data row10 col9\" >0.026833</td>\n",
       "      <td id=\"T_c5b00_row10_col10\" class=\"data row10 col10\" >1.000000</td>\n",
       "      <td id=\"T_c5b00_row10_col11\" class=\"data row10 col11\" >-0.009615</td>\n",
       "      <td id=\"T_c5b00_row10_col12\" class=\"data row10 col12\" >0.006147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5b00_level0_row11\" class=\"row_heading level0 row11\" >duration_ms</th>\n",
       "      <td id=\"T_c5b00_row11_col0\" class=\"data row11 col0\" >-0.053462</td>\n",
       "      <td id=\"T_c5b00_row11_col1\" class=\"data row11 col1\" >-0.193455</td>\n",
       "      <td id=\"T_c5b00_row11_col2\" class=\"data row11 col2\" >0.058517</td>\n",
       "      <td id=\"T_c5b00_row11_col3\" class=\"data row11 col3\" >-0.001163</td>\n",
       "      <td id=\"T_c5b00_row11_col4\" class=\"data row11 col4\" >0.027564</td>\n",
       "      <td id=\"T_c5b00_row11_col5\" class=\"data row11 col5\" >-0.014321</td>\n",
       "      <td id=\"T_c5b00_row11_col6\" class=\"data row11 col6\" >-0.134268</td>\n",
       "      <td id=\"T_c5b00_row11_col7\" class=\"data row11 col7\" >0.003018</td>\n",
       "      <td id=\"T_c5b00_row11_col8\" class=\"data row11 col8\" >0.025322</td>\n",
       "      <td id=\"T_c5b00_row11_col9\" class=\"data row11 col9\" >-0.110459</td>\n",
       "      <td id=\"T_c5b00_row11_col10\" class=\"data row11 col10\" >-0.009615</td>\n",
       "      <td id=\"T_c5b00_row11_col11\" class=\"data row11 col11\" >1.000000</td>\n",
       "      <td id=\"T_c5b00_row11_col12\" class=\"data row11 col12\" >0.029326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5b00_level0_row12\" class=\"row_heading level0 row12\" >time_signature</th>\n",
       "      <td id=\"T_c5b00_row12_col0\" class=\"data row12 col0\" >-0.090135</td>\n",
       "      <td id=\"T_c5b00_row12_col1\" class=\"data row12 col1\" >0.114482</td>\n",
       "      <td id=\"T_c5b00_row12_col2\" class=\"data row12 col2\" >0.082322</td>\n",
       "      <td id=\"T_c5b00_row12_col3\" class=\"data row12 col3\" >-0.004152</td>\n",
       "      <td id=\"T_c5b00_row12_col4\" class=\"data row12 col4\" >0.044661</td>\n",
       "      <td id=\"T_c5b00_row12_col5\" class=\"data row12 col5\" >-0.027352</td>\n",
       "      <td id=\"T_c5b00_row12_col6\" class=\"data row12 col6\" >0.032836</td>\n",
       "      <td id=\"T_c5b00_row12_col7\" class=\"data row12 col7\" >-0.049221</td>\n",
       "      <td id=\"T_c5b00_row12_col8\" class=\"data row12 col8\" >0.017061</td>\n",
       "      <td id=\"T_c5b00_row12_col9\" class=\"data row12 col9\" >0.067634</td>\n",
       "      <td id=\"T_c5b00_row12_col10\" class=\"data row12 col10\" >0.006147</td>\n",
       "      <td id=\"T_c5b00_row12_col11\" class=\"data row12 col11\" >0.029326</td>\n",
       "      <td id=\"T_c5b00_row12_col12\" class=\"data row12 col12\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23c26d753a0>"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_df.corr(method=\"pearson\").style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "9dd67501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>valence</td>     <th>  R-squared:         </th> <td>   0.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   205.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 17 Mar 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:01:19</td>     <th>  Log-Likelihood:    </th> <td>  1260.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5295</td>      <th>  AIC:               </th> <td>  -2496.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5283</td>      <th>  BIC:               </th> <td>  -2417.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>   -0.4479</td> <td>    0.036</td> <td>  -12.518</td> <td> 0.000</td> <td>   -0.518</td> <td>   -0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acousticness</th>     <td>    0.1362</td> <td>    0.016</td> <td>    8.700</td> <td> 0.000</td> <td>    0.106</td> <td>    0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>danceability</th>     <td>    0.6750</td> <td>    0.021</td> <td>   32.655</td> <td> 0.000</td> <td>    0.635</td> <td>    0.716</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>energy</th>           <td>    0.6730</td> <td>    0.024</td> <td>   28.088</td> <td> 0.000</td> <td>    0.626</td> <td>    0.720</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>key</th>              <td>    0.0015</td> <td>    0.001</td> <td>    1.998</td> <td> 0.046</td> <td> 2.77e-05</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loudness</th>         <td>   -0.0095</td> <td>    0.002</td> <td>   -6.016</td> <td> 0.000</td> <td>   -0.013</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mode</th>             <td>   -0.0032</td> <td>    0.005</td> <td>   -0.607</td> <td> 0.544</td> <td>   -0.014</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>speechiness</th>      <td>   -0.1090</td> <td>    0.028</td> <td>   -3.838</td> <td> 0.000</td> <td>   -0.165</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>instrumentalness</th> <td>   -0.1844</td> <td>    0.022</td> <td>   -8.485</td> <td> 0.000</td> <td>   -0.227</td> <td>   -0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>liveness</th>         <td>    0.0032</td> <td>    0.019</td> <td>    0.170</td> <td> 0.865</td> <td>   -0.034</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tempo</th>            <td>    0.0003</td> <td>    0.000</td> <td>    3.408</td> <td> 0.001</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>duration_ms</th>      <td>-3.078e-07</td> <td> 6.29e-08</td> <td>   -4.897</td> <td> 0.000</td> <td>-4.31e-07</td> <td>-1.85e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>49.008</td> <th>  Durbin-Watson:     </th> <td>   1.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  37.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.117</td> <th>  Prob(JB):          </th> <td>6.78e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.660</td> <th>  Cond. No.          </th> <td>3.45e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.45e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                valence   R-squared:                       0.300\n",
       "Model:                            OLS   Adj. R-squared:                  0.299\n",
       "Method:                 Least Squares   F-statistic:                     205.9\n",
       "Date:                Thu, 17 Mar 2022   Prob (F-statistic):               0.00\n",
       "Time:                        17:01:19   Log-Likelihood:                 1260.1\n",
       "No. Observations:                5295   AIC:                            -2496.\n",
       "Df Residuals:                    5283   BIC:                            -2417.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept           -0.4479      0.036    -12.518      0.000      -0.518      -0.378\n",
       "acousticness         0.1362      0.016      8.700      0.000       0.106       0.167\n",
       "danceability         0.6750      0.021     32.655      0.000       0.635       0.716\n",
       "energy               0.6730      0.024     28.088      0.000       0.626       0.720\n",
       "key                  0.0015      0.001      1.998      0.046    2.77e-05       0.003\n",
       "loudness            -0.0095      0.002     -6.016      0.000      -0.013      -0.006\n",
       "mode                -0.0032      0.005     -0.607      0.544      -0.014       0.007\n",
       "speechiness         -0.1090      0.028     -3.838      0.000      -0.165      -0.053\n",
       "instrumentalness    -0.1844      0.022     -8.485      0.000      -0.227      -0.142\n",
       "liveness             0.0032      0.019      0.170      0.865      -0.034       0.040\n",
       "tempo                0.0003      0.000      3.408      0.001       0.000       0.001\n",
       "duration_ms      -3.078e-07   6.29e-08     -4.897      0.000   -4.31e-07   -1.85e-07\n",
       "==============================================================================\n",
       "Omnibus:                       49.008   Durbin-Watson:                   1.764\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               37.618\n",
       "Skew:                          -0.117   Prob(JB):                     6.78e-09\n",
       "Kurtosis:                       2.660   Cond. No.                     3.45e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.45e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols(\"valence ~ acousticness + danceability + energy + key + loudness + mode + speechiness + instrumentalness + liveness + tempo + duration_ms\", data = playlist_df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "993cb3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>danceability</th>\n",
       "      <td>38.877882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1066.339138</td>\n",
       "      <td>3.230166e-213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy</th>\n",
       "      <td>28.764622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>788.953525</td>\n",
       "      <td>6.458495e-162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acousticness</th>\n",
       "      <td>2.759543</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.688509</td>\n",
       "      <td>4.375290e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrumentalness</th>\n",
       "      <td>2.624916</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.995978</td>\n",
       "      <td>2.768292e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loudness</th>\n",
       "      <td>1.319615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.194285</td>\n",
       "      <td>1.906041e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms</th>\n",
       "      <td>0.874203</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.977563</td>\n",
       "      <td>1.003682e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speechiness</th>\n",
       "      <td>0.537033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.729700</td>\n",
       "      <td>1.255252e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempo</th>\n",
       "      <td>0.423393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.612793</td>\n",
       "      <td>6.598904e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <td>0.145584</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.993054</td>\n",
       "      <td>4.573934e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mode</th>\n",
       "      <td>0.013424</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.368191</td>\n",
       "      <td>5.440180e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liveness</th>\n",
       "      <td>0.001049</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028778</td>\n",
       "      <td>8.652987e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>192.614006</td>\n",
       "      <td>5283.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sum_sq      df            F         PR(>F)\n",
       "danceability       38.877882     1.0  1066.339138  3.230166e-213\n",
       "energy             28.764622     1.0   788.953525  6.458495e-162\n",
       "acousticness        2.759543     1.0    75.688509   4.375290e-18\n",
       "instrumentalness    2.624916     1.0    71.995978   2.768292e-17\n",
       "loudness            1.319615     1.0    36.194285   1.906041e-09\n",
       "duration_ms         0.874203     1.0    23.977563   1.003682e-06\n",
       "speechiness         0.537033     1.0    14.729700   1.255252e-04\n",
       "tempo               0.423393     1.0    11.612793   6.598904e-04\n",
       "key                 0.145584     1.0     3.993054   4.573934e-02\n",
       "mode                0.013424     1.0     0.368191   5.440180e-01\n",
       "liveness            0.001049     1.0     0.028778   8.652987e-01\n",
       "Residual          192.614006  5283.0          NaN            NaN"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aov_table = sm.stats.anova_lm(model, typ=2)\n",
    "aov_table.sort_values(by = \"F\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4a097e",
   "metadata": {},
   "source": [
    "Function `process_subset()` takes the dependent variable, the observations, and the set of columns, fits a model, and returns the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "da2d2c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subset(y, data, feature_set):\n",
    "    X = data.loc[:, feature_set].values\n",
    "    X = sm.add_constant(X)\n",
    "    names = ['intercept']\n",
    "    names.extend(feature_set)\n",
    "    model = sm.OLS(y, X)\n",
    "    model.data.xnames = names\n",
    "    regr = model.fit()\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aada493",
   "metadata": {},
   "source": [
    "Function `forward_add_variable()` finds the best variable to add at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "9e9c4daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_add_variable(data, exog, selected, to_select):\n",
    "    best_rsquared = 0\n",
    "    best_model = None\n",
    "    best_column = None\n",
    "    y = data.loc[:, exog]\n",
    "    \n",
    "    for column in to_select:\n",
    "        new_selected = selected + [column]\n",
    "        regr = process_subset(y, data, new_selected)\n",
    "        if regr.rsquared > best_rsquared:\n",
    "            best_rsquared = regr.rsquared\n",
    "            best_model = regr\n",
    "            best_column = column\n",
    "    \n",
    "    return best_model, best_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9331c0d7",
   "metadata": {},
   "source": [
    "Function `forward_stepwise_selection()` that just does a loop adding a variable at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "18fca9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_stepwise_selection(data, exog):\n",
    "\n",
    "    best_models = []\n",
    "    best_model = None\n",
    "    selected = []\n",
    "    to_select = [ x for x in data.columns if x != exog ]\n",
    "\n",
    "    p = len(to_select) + 1\n",
    "\n",
    "    for i in range(1, p):\n",
    "        print(f'Finding the best model for {i} variable{\"s\" if i > 1 else \"\"}')\n",
    "        model, best_column = forward_add_variable(data, exog, selected, to_select)\n",
    "        selected.append(best_column)\n",
    "        to_select.remove(best_column)\n",
    "        if not best_model or model.rsquared_adj > best_model.rsquared_adj:\n",
    "            best_model = model\n",
    "        print(selected)\n",
    "        best_models.append(model)\n",
    "        \n",
    "    print(f'Fitted {1 + p*(p+1)//2} models')\n",
    "    return best_model, best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "1b168ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the best model for 1 variable\n",
      "['danceability']\n",
      "Finding the best model for 2 variables\n",
      "['danceability', 'energy']\n",
      "Finding the best model for 3 variables\n",
      "['danceability', 'energy', 'acousticness']\n",
      "Finding the best model for 4 variables\n",
      "['danceability', 'energy', 'acousticness', 'instrumentalness']\n",
      "Finding the best model for 5 variables\n",
      "['danceability', 'energy', 'acousticness', 'instrumentalness', 'loudness']\n",
      "Finding the best model for 6 variables\n",
      "['danceability', 'energy', 'acousticness', 'instrumentalness', 'loudness', 'duration_ms']\n",
      "Finding the best model for 7 variables\n",
      "['danceability', 'energy', 'acousticness', 'instrumentalness', 'loudness', 'duration_ms', 'speechiness']\n",
      "Finding the best model for 8 variables\n",
      "['danceability', 'energy', 'acousticness', 'instrumentalness', 'loudness', 'duration_ms', 'speechiness', 'tempo']\n",
      "Finding the best model for 9 variables\n",
      "['danceability', 'energy', 'acousticness', 'instrumentalness', 'loudness', 'duration_ms', 'speechiness', 'tempo', 'key']\n",
      "Finding the best model for 10 variables\n",
      "['danceability', 'energy', 'acousticness', 'instrumentalness', 'loudness', 'duration_ms', 'speechiness', 'tempo', 'key', 'mode']\n",
      "Finding the best model for 11 variables\n",
      "['danceability', 'energy', 'acousticness', 'instrumentalness', 'loudness', 'duration_ms', 'speechiness', 'tempo', 'key', 'mode', 'time_signature']\n",
      "Finding the best model for 12 variables\n",
      "['danceability', 'energy', 'acousticness', 'instrumentalness', 'loudness', 'duration_ms', 'speechiness', 'tempo', 'key', 'mode', 'time_signature', 'liveness']\n",
      "Fitted 92 models\n",
      "Best overall model: 10 ['intercept', 'danceability', 'energy', 'acousticness', 'instrumentalness', 'loudness', 'duration_ms', 'speechiness', 'tempo', 'key']\n"
     ]
    }
   ],
   "source": [
    "best_model, _ = forward_stepwise_selection(playlist_df.drop(columns=[\"track_id\", \"track_name\", \"album\", \"artist\"]), 'valence')\n",
    "print('Best overall model:', len(best_model.model.exog_names), best_model.model.exog_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "81be52a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>valence</td>     <th>  R-squared:         </th> <td>   0.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   251.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 17 Mar 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:01:20</td>     <th>  Log-Likelihood:    </th> <td>  1259.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5295</td>      <th>  AIC:               </th> <td>  -2500.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5285</td>      <th>  BIC:               </th> <td>  -2434.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>        <td>   -0.4503</td> <td>    0.035</td> <td>  -12.734</td> <td> 0.000</td> <td>   -0.520</td> <td>   -0.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>danceability</th>     <td>    0.6751</td> <td>    0.021</td> <td>   32.831</td> <td> 0.000</td> <td>    0.635</td> <td>    0.715</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>energy</th>           <td>    0.6738</td> <td>    0.024</td> <td>   28.332</td> <td> 0.000</td> <td>    0.627</td> <td>    0.720</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acousticness</th>     <td>    0.1361</td> <td>    0.016</td> <td>    8.694</td> <td> 0.000</td> <td>    0.105</td> <td>    0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>instrumentalness</th> <td>   -0.1843</td> <td>    0.022</td> <td>   -8.483</td> <td> 0.000</td> <td>   -0.227</td> <td>   -0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loudness</th>         <td>   -0.0095</td> <td>    0.002</td> <td>   -6.029</td> <td> 0.000</td> <td>   -0.013</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>duration_ms</th>      <td> -3.07e-07</td> <td> 6.28e-08</td> <td>   -4.886</td> <td> 0.000</td> <td> -4.3e-07</td> <td>-1.84e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>speechiness</th>      <td>   -0.1085</td> <td>    0.028</td> <td>   -3.838</td> <td> 0.000</td> <td>   -0.164</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tempo</th>            <td>    0.0003</td> <td>    0.000</td> <td>    3.400</td> <td> 0.001</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>key</th>              <td>    0.0015</td> <td>    0.001</td> <td>    2.119</td> <td> 0.034</td> <td>    0.000</td> <td>    0.003</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>48.802</td> <th>  Durbin-Watson:     </th> <td>   1.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  37.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.117</td> <th>  Prob(JB):          </th> <td>7.18e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.661</td> <th>  Cond. No.          </th> <td>3.43e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.43e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                valence   R-squared:                       0.300\n",
       "Model:                            OLS   Adj. R-squared:                  0.299\n",
       "Method:                 Least Squares   F-statistic:                     251.7\n",
       "Date:                Thu, 17 Mar 2022   Prob (F-statistic):               0.00\n",
       "Time:                        17:01:20   Log-Likelihood:                 1259.9\n",
       "No. Observations:                5295   AIC:                            -2500.\n",
       "Df Residuals:                    5285   BIC:                            -2434.\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "intercept           -0.4503      0.035    -12.734      0.000      -0.520      -0.381\n",
       "danceability         0.6751      0.021     32.831      0.000       0.635       0.715\n",
       "energy               0.6738      0.024     28.332      0.000       0.627       0.720\n",
       "acousticness         0.1361      0.016      8.694      0.000       0.105       0.167\n",
       "instrumentalness    -0.1843      0.022     -8.483      0.000      -0.227      -0.142\n",
       "loudness            -0.0095      0.002     -6.029      0.000      -0.013      -0.006\n",
       "duration_ms       -3.07e-07   6.28e-08     -4.886      0.000    -4.3e-07   -1.84e-07\n",
       "speechiness         -0.1085      0.028     -3.838      0.000      -0.164      -0.053\n",
       "tempo                0.0003      0.000      3.400      0.001       0.000       0.001\n",
       "key                  0.0015      0.001      2.119      0.034       0.000       0.003\n",
       "==============================================================================\n",
       "Omnibus:                       48.802   Durbin-Watson:                   1.764\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               37.505\n",
       "Skew:                          -0.117   Prob(JB):                     7.18e-09\n",
       "Kurtosis:                       2.661   Cond. No.                     3.43e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.43e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139dac3d",
   "metadata": {},
   "source": [
    "* As we see from the models above the features that mostly influence the valence are danceability and energy \\newline\n",
    "* Although other features seem to have some small influence too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead4454",
   "metadata": {},
   "source": [
    "### Q2: Predict Valence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2d5285",
   "metadata": {},
   "source": [
    "Using Machine Learning techniques to predict valence based on track features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "ae9aab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import SCORERS\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2164b57",
   "metadata": {},
   "source": [
    "Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "492ee84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_df.drop(columns=[\"track_id\", \"track_name\", \"album\", \"artist\"], inplace=True)\n",
    "X = playlist_df.drop(columns = [\"valence\"])\n",
    "y = playlist_df[\"valence\"]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acdc4d5",
   "metadata": {},
   "source": [
    "### Using the Lars regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "4c105d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "{'verbose': False, 'precompute': False, 'normalize': True, 'n_nonzero_coefs': 10, 'fit_path': False, 'fit_intercept': True, 'copy_X': True}\n"
     ]
    }
   ],
   "source": [
    "lars = Lars()\n",
    "random_grid = {'n_nonzero_coefs': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'fit_intercept': [True, False],\n",
    "            'verbose': [True, False],\n",
    "            'normalize': [True, False],\n",
    "            'precompute': [True, False],\n",
    "            'copy_X': [True, False],\n",
    "            'fit_path': [True, False]}\n",
    "random_search = RandomizedSearchCV(estimator = lars, param_distributions = random_grid, n_iter = 30, cv = 3, verbose=2, random_state=42, n_jobs = -1, scoring = 'r2')\n",
    "random_search.fit(xtrain, ytrain)\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "d4afb454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.293\n",
      "MAE: 0.154 \n"
     ]
    }
   ],
   "source": [
    "best_lars = random_search.best_estimator_\n",
    "best_lars.fit(xtrain, ytrain)\n",
    "lars_pred = best_lars.predict(xtest)\n",
    "print(\"R2: {:.3f}\".format(r2_score(ytest, lars_pred)))\n",
    "print(\"MAE: {:.3f} \" .format(mean_absolute_error(ytest, lars_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3d44a4",
   "metadata": {},
   "source": [
    "### Using the random forest regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "fc895ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'bootstrap': [True, False],\n",
    " 'max_depth': [80, 90, 100, 110],\n",
    " 'max_features': [2, 3],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [100, 200, 400, 600, 800,1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "254b8726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "{'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 3, 'max_depth': 100, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "random = RandomizedSearchCV(estimator = rfr, param_distributions = grid, n_iter = 20, cv = 3, verbose=2, random_state=42, n_jobs = -1,scoring = 'r2')\n",
    "searchResults = random.fit(xtrain, ytrain)\n",
    "print(searchResults.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "89942749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.389\n",
      "MAE: 0.141 \n"
     ]
    }
   ],
   "source": [
    "bestRFR = searchResults.best_estimator_\n",
    "y_pred = bestRFR.predict(xtest)\n",
    "print(\"R2: {:.3f}\".format(r2_score(ytest, y_pred)))\n",
    "print(\"MAE: {:.3f} \".format(mean_absolute_error(ytest, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d133e23d",
   "metadata": {},
   "source": [
    "### Using the XGB reggresion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "d2fd4ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_xgb = {'booster': ['gbtree', 'gblinear', 'dart'],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8],\n",
    "    'gamma': [0.0, 0.1, 0.2],\n",
    "    'learning_rate': [0.01, 0.02, 0.03, 0.04],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_child_weight': [1, 2, 3, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "9cb797cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "{'min_child_weight': 1, 'max_depth': 5, 'learning_rate': 0.04, 'gamma': 0.0, 'colsample_bytree': 0.6, 'booster': 'gbtree'}\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor()\n",
    "random = RandomizedSearchCV(estimator = xgb_model, param_distributions = grid_xgb, n_iter = 20, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "searchResults = random.fit(xtrain, ytrain)\n",
    "print(searchResults.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "d87a930a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.346\n",
      "MAE: 0.149 \n"
     ]
    }
   ],
   "source": [
    "bestXGB = searchResults.best_estimator_\n",
    "y_pred = bestXGB.predict(xtest)\n",
    "print(\"R2: {:.3f}\".format(r2_score(ytest, y_pred)))\n",
    "print(\"MAE: {:.3f} \".format(mean_absolute_error(ytest, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "563aecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {'bootstrap': [True, False],\n",
    "  'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
    "  'max_features': ['auto', 'sqrt'],\n",
    "  'min_samples_leaf': [1, 2, 4],\n",
    "  'min_samples_split': [2, 5, 10],\n",
    "  'n_estimators': [200, 400, 500, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eba95b",
   "metadata": {},
   "source": [
    "### Using the Extra Trees reggresion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "711ea068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "{'min_child_weight': 1, 'max_depth': 5, 'learning_rate': 0.04, 'gamma': 0.0, 'colsample_bytree': 0.6, 'booster': 'gbtree'}\n"
     ]
    }
   ],
   "source": [
    "#import extratrees \n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "et = ExtraTreesRegressor()\n",
    "et_random = RandomizedSearchCV(estimator = et, param_distributions = random_grid, n_iter = 20, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "et_random.fit(xtrain, ytrain)\n",
    "print(searchResults.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "d3e57971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.382\n",
      "MAE: 0.140 \n"
     ]
    }
   ],
   "source": [
    "bestET = et_random.best_estimator_\n",
    "y_pred = bestET.predict(xtest)\n",
    "print(\"R2: {:.3f}\".format(r2_score(ytest, y_pred)))\n",
    "print(\"MAE: {:.3f} \".format(mean_absolute_error(ytest, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbbcc63",
   "metadata": {},
   "source": [
    "### Creating a Neural Network for Reggresion to predict valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "f9614244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import utils\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import History\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import scikeras\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "7fc3afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1000\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='mean_absolute_error', mode='min', verbose=1, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "f4c12332",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "3efe2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm):\n",
    "    model = keras.Sequential([\n",
    "        norm,\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mean_absolute_error', optimizer=SGD(0.1), metrics=['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "bcb682b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_2 (Normalizat  (None, 12)               25        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                416       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,114\n",
      "Trainable params: 1,089\n",
      "Non-trainable params: 25\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    dnn = build_and_compile_model(normalizer)\n",
    "    dnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587867de",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "f6a64e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "133/133 [==============================] - 1s 2ms/step - loss: 0.2352 - mean_absolute_error: 0.2352 - val_loss: 0.1932 - val_mean_absolute_error: 0.1932\n",
      "Epoch 2/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1839 - mean_absolute_error: 0.1839 - val_loss: 0.1797 - val_mean_absolute_error: 0.1797\n",
      "Epoch 3/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1744 - mean_absolute_error: 0.1744 - val_loss: 0.1795 - val_mean_absolute_error: 0.1795\n",
      "Epoch 4/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1700 - mean_absolute_error: 0.1700 - val_loss: 0.1703 - val_mean_absolute_error: 0.1703\n",
      "Epoch 5/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1672 - mean_absolute_error: 0.1672 - val_loss: 0.1704 - val_mean_absolute_error: 0.1704\n",
      "Epoch 6/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1650 - mean_absolute_error: 0.1650 - val_loss: 0.1716 - val_mean_absolute_error: 0.1716\n",
      "Epoch 7/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1634 - mean_absolute_error: 0.1634 - val_loss: 0.1664 - val_mean_absolute_error: 0.1664\n",
      "Epoch 8/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1621 - mean_absolute_error: 0.1621 - val_loss: 0.1658 - val_mean_absolute_error: 0.1658\n",
      "Epoch 9/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1608 - mean_absolute_error: 0.1608 - val_loss: 0.1649 - val_mean_absolute_error: 0.1649\n",
      "Epoch 10/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1596 - mean_absolute_error: 0.1596 - val_loss: 0.1669 - val_mean_absolute_error: 0.1669\n",
      "Epoch 11/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1590 - mean_absolute_error: 0.1590 - val_loss: 0.1658 - val_mean_absolute_error: 0.1658\n",
      "Epoch 12/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1582 - mean_absolute_error: 0.1582 - val_loss: 0.1640 - val_mean_absolute_error: 0.1640\n",
      "Epoch 13/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1573 - mean_absolute_error: 0.1573 - val_loss: 0.1631 - val_mean_absolute_error: 0.1631\n",
      "Epoch 14/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1565 - mean_absolute_error: 0.1565 - val_loss: 0.1628 - val_mean_absolute_error: 0.1628\n",
      "Epoch 15/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1561 - mean_absolute_error: 0.1561 - val_loss: 0.1625 - val_mean_absolute_error: 0.1625\n",
      "Epoch 16/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1555 - mean_absolute_error: 0.1555 - val_loss: 0.1653 - val_mean_absolute_error: 0.1653\n",
      "Epoch 17/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1550 - mean_absolute_error: 0.1550 - val_loss: 0.1634 - val_mean_absolute_error: 0.1634\n",
      "Epoch 18/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1545 - mean_absolute_error: 0.1545 - val_loss: 0.1615 - val_mean_absolute_error: 0.1615\n",
      "Epoch 19/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1542 - mean_absolute_error: 0.1542 - val_loss: 0.1628 - val_mean_absolute_error: 0.1628\n",
      "Epoch 20/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1535 - mean_absolute_error: 0.1535 - val_loss: 0.1626 - val_mean_absolute_error: 0.1626\n",
      "Epoch 21/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1533 - mean_absolute_error: 0.1533 - val_loss: 0.1615 - val_mean_absolute_error: 0.1615\n",
      "Epoch 22/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1529 - mean_absolute_error: 0.1529 - val_loss: 0.1619 - val_mean_absolute_error: 0.1619\n",
      "Epoch 23/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1524 - mean_absolute_error: 0.1524 - val_loss: 0.1607 - val_mean_absolute_error: 0.1607\n",
      "Epoch 24/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1521 - mean_absolute_error: 0.1521 - val_loss: 0.1621 - val_mean_absolute_error: 0.1621\n",
      "Epoch 25/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1519 - mean_absolute_error: 0.1519 - val_loss: 0.1606 - val_mean_absolute_error: 0.1606\n",
      "Epoch 26/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1516 - mean_absolute_error: 0.1516 - val_loss: 0.1615 - val_mean_absolute_error: 0.1615\n",
      "Epoch 27/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1515 - mean_absolute_error: 0.1515 - val_loss: 0.1606 - val_mean_absolute_error: 0.1606\n",
      "Epoch 28/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1509 - mean_absolute_error: 0.1509 - val_loss: 0.1606 - val_mean_absolute_error: 0.1606\n",
      "Epoch 29/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1508 - mean_absolute_error: 0.1508 - val_loss: 0.1599 - val_mean_absolute_error: 0.1599\n",
      "Epoch 30/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1505 - mean_absolute_error: 0.1505 - val_loss: 0.1622 - val_mean_absolute_error: 0.1622\n",
      "Epoch 31/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1622 - val_mean_absolute_error: 0.1622\n",
      "Epoch 32/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1501 - mean_absolute_error: 0.1501 - val_loss: 0.1600 - val_mean_absolute_error: 0.1600\n",
      "Epoch 33/1000\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1499 - mean_absolute_error: 0.1499 - val_loss: 0.1599 - val_mean_absolute_error: 0.1599\n",
      "Epoch 34/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1495 - mean_absolute_error: 0.1495 - val_loss: 0.1612 - val_mean_absolute_error: 0.1612\n",
      "Epoch 35/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1495 - mean_absolute_error: 0.1495 - val_loss: 0.1594 - val_mean_absolute_error: 0.1594\n",
      "Epoch 36/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1490 - mean_absolute_error: 0.1490 - val_loss: 0.1627 - val_mean_absolute_error: 0.1627\n",
      "Epoch 37/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1491 - mean_absolute_error: 0.1491 - val_loss: 0.1591 - val_mean_absolute_error: 0.1591\n",
      "Epoch 38/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1489 - mean_absolute_error: 0.1489 - val_loss: 0.1595 - val_mean_absolute_error: 0.1595\n",
      "Epoch 39/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1485 - mean_absolute_error: 0.1485 - val_loss: 0.1588 - val_mean_absolute_error: 0.1588\n",
      "Epoch 40/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1483 - mean_absolute_error: 0.1483 - val_loss: 0.1589 - val_mean_absolute_error: 0.1589\n",
      "Epoch 41/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1482 - mean_absolute_error: 0.1482 - val_loss: 0.1594 - val_mean_absolute_error: 0.1594\n",
      "Epoch 42/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1480 - mean_absolute_error: 0.1480 - val_loss: 0.1585 - val_mean_absolute_error: 0.1585\n",
      "Epoch 43/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1479 - mean_absolute_error: 0.1479 - val_loss: 0.1592 - val_mean_absolute_error: 0.1592\n",
      "Epoch 44/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1475 - mean_absolute_error: 0.1475 - val_loss: 0.1601 - val_mean_absolute_error: 0.1601\n",
      "Epoch 45/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1476 - mean_absolute_error: 0.1476 - val_loss: 0.1584 - val_mean_absolute_error: 0.1584\n",
      "Epoch 46/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1474 - mean_absolute_error: 0.1474 - val_loss: 0.1591 - val_mean_absolute_error: 0.1591\n",
      "Epoch 47/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1472 - mean_absolute_error: 0.1472 - val_loss: 0.1590 - val_mean_absolute_error: 0.1590\n",
      "Epoch 48/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1471 - mean_absolute_error: 0.1471 - val_loss: 0.1581 - val_mean_absolute_error: 0.1581\n",
      "Epoch 49/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1470 - mean_absolute_error: 0.1470 - val_loss: 0.1587 - val_mean_absolute_error: 0.1587\n",
      "Epoch 50/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1467 - mean_absolute_error: 0.1467 - val_loss: 0.1579 - val_mean_absolute_error: 0.1579\n",
      "Epoch 51/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1467 - mean_absolute_error: 0.1467 - val_loss: 0.1581 - val_mean_absolute_error: 0.1581\n",
      "Epoch 52/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1464 - mean_absolute_error: 0.1464 - val_loss: 0.1583 - val_mean_absolute_error: 0.1583\n",
      "Epoch 53/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1464 - mean_absolute_error: 0.1464 - val_loss: 0.1585 - val_mean_absolute_error: 0.1585\n",
      "Epoch 54/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1463 - mean_absolute_error: 0.1463 - val_loss: 0.1580 - val_mean_absolute_error: 0.1580\n",
      "Epoch 55/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1460 - mean_absolute_error: 0.1460 - val_loss: 0.1577 - val_mean_absolute_error: 0.1577\n",
      "Epoch 56/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1459 - mean_absolute_error: 0.1459 - val_loss: 0.1576 - val_mean_absolute_error: 0.1576\n",
      "Epoch 57/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1458 - mean_absolute_error: 0.1458 - val_loss: 0.1580 - val_mean_absolute_error: 0.1580\n",
      "Epoch 58/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1457 - mean_absolute_error: 0.1457 - val_loss: 0.1575 - val_mean_absolute_error: 0.1575\n",
      "Epoch 59/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1454 - mean_absolute_error: 0.1454 - val_loss: 0.1576 - val_mean_absolute_error: 0.1576\n",
      "Epoch 60/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1456 - mean_absolute_error: 0.1456 - val_loss: 0.1576 - val_mean_absolute_error: 0.1576\n",
      "Epoch 61/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1453 - mean_absolute_error: 0.1453 - val_loss: 0.1576 - val_mean_absolute_error: 0.1576\n",
      "Epoch 62/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1451 - mean_absolute_error: 0.1451 - val_loss: 0.1589 - val_mean_absolute_error: 0.1589\n",
      "Epoch 63/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1451 - mean_absolute_error: 0.1451 - val_loss: 0.1577 - val_mean_absolute_error: 0.1577\n",
      "Epoch 64/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1450 - mean_absolute_error: 0.1450 - val_loss: 0.1575 - val_mean_absolute_error: 0.1575\n",
      "Epoch 65/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1449 - mean_absolute_error: 0.1449 - val_loss: 0.1581 - val_mean_absolute_error: 0.1581\n",
      "Epoch 66/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1447 - mean_absolute_error: 0.1447 - val_loss: 0.1577 - val_mean_absolute_error: 0.1577\n",
      "Epoch 67/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1447 - mean_absolute_error: 0.1447 - val_loss: 0.1579 - val_mean_absolute_error: 0.1579\n",
      "Epoch 68/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1446 - mean_absolute_error: 0.1446 - val_loss: 0.1585 - val_mean_absolute_error: 0.1585\n",
      "Epoch 69/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1444 - mean_absolute_error: 0.1444 - val_loss: 0.1575 - val_mean_absolute_error: 0.1575\n",
      "Epoch 70/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1443 - mean_absolute_error: 0.1443 - val_loss: 0.1578 - val_mean_absolute_error: 0.1578\n",
      "Epoch 71/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1442 - mean_absolute_error: 0.1442 - val_loss: 0.1591 - val_mean_absolute_error: 0.1591\n",
      "Epoch 72/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1442 - mean_absolute_error: 0.1442 - val_loss: 0.1578 - val_mean_absolute_error: 0.1578\n",
      "Epoch 73/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1442 - mean_absolute_error: 0.1442 - val_loss: 0.1576 - val_mean_absolute_error: 0.1576\n",
      "Epoch 74/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1439 - mean_absolute_error: 0.1439 - val_loss: 0.1572 - val_mean_absolute_error: 0.1572\n",
      "Epoch 75/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1439 - mean_absolute_error: 0.1439 - val_loss: 0.1575 - val_mean_absolute_error: 0.1575\n",
      "Epoch 76/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1438 - mean_absolute_error: 0.1438 - val_loss: 0.1572 - val_mean_absolute_error: 0.1572\n",
      "Epoch 77/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1435 - mean_absolute_error: 0.1435 - val_loss: 0.1583 - val_mean_absolute_error: 0.1583\n",
      "Epoch 78/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1433 - mean_absolute_error: 0.1433 - val_loss: 0.1573 - val_mean_absolute_error: 0.1573\n",
      "Epoch 79/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1433 - mean_absolute_error: 0.1433 - val_loss: 0.1584 - val_mean_absolute_error: 0.1584\n",
      "Epoch 80/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1434 - mean_absolute_error: 0.1434 - val_loss: 0.1589 - val_mean_absolute_error: 0.1589\n",
      "Epoch 81/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1433 - mean_absolute_error: 0.1433 - val_loss: 0.1572 - val_mean_absolute_error: 0.1572\n",
      "Epoch 82/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1433 - mean_absolute_error: 0.1433 - val_loss: 0.1578 - val_mean_absolute_error: 0.1578\n",
      "Epoch 83/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1432 - mean_absolute_error: 0.1432 - val_loss: 0.1586 - val_mean_absolute_error: 0.1586\n",
      "Epoch 84/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1430 - mean_absolute_error: 0.1430 - val_loss: 0.1585 - val_mean_absolute_error: 0.1585\n",
      "Epoch 85/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1429 - mean_absolute_error: 0.1429 - val_loss: 0.1583 - val_mean_absolute_error: 0.1583\n",
      "Epoch 86/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1427 - mean_absolute_error: 0.1427 - val_loss: 0.1574 - val_mean_absolute_error: 0.1574\n",
      "Epoch 87/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1426 - mean_absolute_error: 0.1426 - val_loss: 0.1575 - val_mean_absolute_error: 0.1575\n",
      "Epoch 88/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1426 - mean_absolute_error: 0.1426 - val_loss: 0.1614 - val_mean_absolute_error: 0.1614\n",
      "Epoch 89/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1426 - mean_absolute_error: 0.1426 - val_loss: 0.1577 - val_mean_absolute_error: 0.1577\n",
      "Epoch 90/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1423 - mean_absolute_error: 0.1423 - val_loss: 0.1573 - val_mean_absolute_error: 0.1573\n",
      "Epoch 91/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1423 - mean_absolute_error: 0.1423 - val_loss: 0.1602 - val_mean_absolute_error: 0.1602\n",
      "Epoch 92/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1423 - mean_absolute_error: 0.1423 - val_loss: 0.1580 - val_mean_absolute_error: 0.1580\n",
      "Epoch 93/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1422 - mean_absolute_error: 0.1422 - val_loss: 0.1573 - val_mean_absolute_error: 0.1573\n",
      "Epoch 94/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1420 - mean_absolute_error: 0.1420 - val_loss: 0.1595 - val_mean_absolute_error: 0.1595\n",
      "Epoch 95/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1420 - mean_absolute_error: 0.1420 - val_loss: 0.1579 - val_mean_absolute_error: 0.1579\n",
      "Epoch 96/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1419 - mean_absolute_error: 0.1419 - val_loss: 0.1592 - val_mean_absolute_error: 0.1592\n",
      "Epoch 97/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1418 - mean_absolute_error: 0.1418 - val_loss: 0.1592 - val_mean_absolute_error: 0.1592\n",
      "Epoch 98/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1416 - mean_absolute_error: 0.1416 - val_loss: 0.1575 - val_mean_absolute_error: 0.1575\n",
      "Epoch 99/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1417 - mean_absolute_error: 0.1417 - val_loss: 0.1577 - val_mean_absolute_error: 0.1577\n",
      "Epoch 100/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1415 - mean_absolute_error: 0.1415 - val_loss: 0.1586 - val_mean_absolute_error: 0.1586\n",
      "Epoch 101/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1413 - mean_absolute_error: 0.1413 - val_loss: 0.1576 - val_mean_absolute_error: 0.1576\n",
      "Epoch 102/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1412 - mean_absolute_error: 0.1412 - val_loss: 0.1584 - val_mean_absolute_error: 0.1584\n",
      "Epoch 103/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1413 - mean_absolute_error: 0.1413 - val_loss: 0.1603 - val_mean_absolute_error: 0.1603\n",
      "Epoch 104/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1412 - mean_absolute_error: 0.1412 - val_loss: 0.1576 - val_mean_absolute_error: 0.1576\n",
      "Epoch 105/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1413 - mean_absolute_error: 0.1413 - val_loss: 0.1580 - val_mean_absolute_error: 0.1580\n",
      "Epoch 106/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1410 - mean_absolute_error: 0.1410 - val_loss: 0.1591 - val_mean_absolute_error: 0.1591\n",
      "Epoch 107/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1410 - mean_absolute_error: 0.1410 - val_loss: 0.1592 - val_mean_absolute_error: 0.1592\n",
      "Epoch 108/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1409 - mean_absolute_error: 0.1409 - val_loss: 0.1607 - val_mean_absolute_error: 0.1607\n",
      "Epoch 109/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1410 - mean_absolute_error: 0.1410 - val_loss: 0.1586 - val_mean_absolute_error: 0.1586\n",
      "Epoch 110/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1408 - mean_absolute_error: 0.1408 - val_loss: 0.1579 - val_mean_absolute_error: 0.1579\n",
      "Epoch 111/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1409 - mean_absolute_error: 0.1409 - val_loss: 0.1581 - val_mean_absolute_error: 0.1581\n",
      "Epoch 112/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1406 - mean_absolute_error: 0.1406 - val_loss: 0.1583 - val_mean_absolute_error: 0.1583\n",
      "Epoch 113/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1405 - mean_absolute_error: 0.1405 - val_loss: 0.1587 - val_mean_absolute_error: 0.1587\n",
      "Epoch 114/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1406 - mean_absolute_error: 0.1406 - val_loss: 0.1586 - val_mean_absolute_error: 0.1586\n",
      "Epoch 115/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1404 - mean_absolute_error: 0.1404 - val_loss: 0.1593 - val_mean_absolute_error: 0.1593\n",
      "Epoch 116/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1404 - mean_absolute_error: 0.1404 - val_loss: 0.1588 - val_mean_absolute_error: 0.1588\n",
      "Epoch 117/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1402 - mean_absolute_error: 0.1402 - val_loss: 0.1586 - val_mean_absolute_error: 0.1586\n",
      "Epoch 118/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1404 - mean_absolute_error: 0.1404 - val_loss: 0.1595 - val_mean_absolute_error: 0.1595\n",
      "Epoch 119/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1400 - mean_absolute_error: 0.1400 - val_loss: 0.1583 - val_mean_absolute_error: 0.1583\n",
      "Epoch 120/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1401 - mean_absolute_error: 0.1401 - val_loss: 0.1587 - val_mean_absolute_error: 0.1587\n",
      "Epoch 121/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1399 - mean_absolute_error: 0.1399 - val_loss: 0.1590 - val_mean_absolute_error: 0.1590\n",
      "Epoch 122/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1400 - mean_absolute_error: 0.1400 - val_loss: 0.1583 - val_mean_absolute_error: 0.1583\n",
      "Epoch 123/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1400 - mean_absolute_error: 0.1400 - val_loss: 0.1613 - val_mean_absolute_error: 0.1613\n",
      "Epoch 124/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1399 - mean_absolute_error: 0.1399 - val_loss: 0.1585 - val_mean_absolute_error: 0.1585\n",
      "Epoch 125/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1398 - mean_absolute_error: 0.1398 - val_loss: 0.1602 - val_mean_absolute_error: 0.1602\n",
      "Epoch 126/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1395 - mean_absolute_error: 0.1395 - val_loss: 0.1599 - val_mean_absolute_error: 0.1599\n",
      "Epoch 127/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1396 - mean_absolute_error: 0.1396 - val_loss: 0.1583 - val_mean_absolute_error: 0.1583\n",
      "Epoch 128/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1396 - mean_absolute_error: 0.1396 - val_loss: 0.1594 - val_mean_absolute_error: 0.1594\n",
      "Epoch 129/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1396 - mean_absolute_error: 0.1396 - val_loss: 0.1583 - val_mean_absolute_error: 0.1583\n",
      "Epoch 130/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1396 - mean_absolute_error: 0.1396 - val_loss: 0.1589 - val_mean_absolute_error: 0.1589\n",
      "Epoch 131/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1394 - mean_absolute_error: 0.1394 - val_loss: 0.1589 - val_mean_absolute_error: 0.1589\n",
      "Epoch 132/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1393 - mean_absolute_error: 0.1393 - val_loss: 0.1585 - val_mean_absolute_error: 0.1585\n",
      "Epoch 133/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1393 - mean_absolute_error: 0.1393 - val_loss: 0.1603 - val_mean_absolute_error: 0.1603\n",
      "Epoch 134/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1393 - mean_absolute_error: 0.1393 - val_loss: 0.1621 - val_mean_absolute_error: 0.1621\n",
      "Epoch 135/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1390 - mean_absolute_error: 0.1390 - val_loss: 0.1591 - val_mean_absolute_error: 0.1591\n",
      "Epoch 136/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1390 - mean_absolute_error: 0.1390 - val_loss: 0.1605 - val_mean_absolute_error: 0.1605\n",
      "Epoch 137/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1390 - mean_absolute_error: 0.1390 - val_loss: 0.1587 - val_mean_absolute_error: 0.1587\n",
      "Epoch 138/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1392 - mean_absolute_error: 0.1392 - val_loss: 0.1589 - val_mean_absolute_error: 0.1589\n",
      "Epoch 139/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1389 - mean_absolute_error: 0.1389 - val_loss: 0.1598 - val_mean_absolute_error: 0.1598\n",
      "Epoch 140/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1388 - mean_absolute_error: 0.1388 - val_loss: 0.1600 - val_mean_absolute_error: 0.1600\n",
      "Epoch 141/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1387 - mean_absolute_error: 0.1387 - val_loss: 0.1589 - val_mean_absolute_error: 0.1589\n",
      "Epoch 142/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1387 - mean_absolute_error: 0.1387 - val_loss: 0.1606 - val_mean_absolute_error: 0.1606\n",
      "Epoch 143/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1387 - mean_absolute_error: 0.1387 - val_loss: 0.1590 - val_mean_absolute_error: 0.1590\n",
      "Epoch 144/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1387 - mean_absolute_error: 0.1387 - val_loss: 0.1617 - val_mean_absolute_error: 0.1617\n",
      "Epoch 145/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1386 - mean_absolute_error: 0.1386 - val_loss: 0.1591 - val_mean_absolute_error: 0.1591\n",
      "Epoch 146/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1384 - mean_absolute_error: 0.1384 - val_loss: 0.1594 - val_mean_absolute_error: 0.1594\n",
      "Epoch 147/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1384 - mean_absolute_error: 0.1384 - val_loss: 0.1616 - val_mean_absolute_error: 0.1616\n",
      "Epoch 148/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1383 - mean_absolute_error: 0.1383 - val_loss: 0.1593 - val_mean_absolute_error: 0.1593\n",
      "Epoch 149/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1384 - mean_absolute_error: 0.1384 - val_loss: 0.1597 - val_mean_absolute_error: 0.1597\n",
      "Epoch 150/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1381 - mean_absolute_error: 0.1381 - val_loss: 0.1604 - val_mean_absolute_error: 0.1604\n",
      "Epoch 151/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1381 - mean_absolute_error: 0.1381 - val_loss: 0.1614 - val_mean_absolute_error: 0.1614\n",
      "Epoch 152/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1381 - mean_absolute_error: 0.1381 - val_loss: 0.1601 - val_mean_absolute_error: 0.1601\n",
      "Epoch 153/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1381 - mean_absolute_error: 0.1381 - val_loss: 0.1597 - val_mean_absolute_error: 0.1597\n",
      "Epoch 154/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1381 - mean_absolute_error: 0.1381 - val_loss: 0.1596 - val_mean_absolute_error: 0.1596\n",
      "Epoch 155/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1378 - mean_absolute_error: 0.1378 - val_loss: 0.1622 - val_mean_absolute_error: 0.1622\n",
      "Epoch 156/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1377 - mean_absolute_error: 0.1377 - val_loss: 0.1595 - val_mean_absolute_error: 0.1595\n",
      "Epoch 157/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1378 - mean_absolute_error: 0.1378 - val_loss: 0.1594 - val_mean_absolute_error: 0.1594\n",
      "Epoch 158/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1376 - mean_absolute_error: 0.1376 - val_loss: 0.1592 - val_mean_absolute_error: 0.1592\n",
      "Epoch 159/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1377 - mean_absolute_error: 0.1377 - val_loss: 0.1595 - val_mean_absolute_error: 0.1595\n",
      "Epoch 160/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1377 - mean_absolute_error: 0.1377 - val_loss: 0.1601 - val_mean_absolute_error: 0.1601\n",
      "Epoch 161/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1377 - mean_absolute_error: 0.1377 - val_loss: 0.1612 - val_mean_absolute_error: 0.1612\n",
      "Epoch 162/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1373 - mean_absolute_error: 0.1373 - val_loss: 0.1591 - val_mean_absolute_error: 0.1591\n",
      "Epoch 163/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1374 - mean_absolute_error: 0.1374 - val_loss: 0.1598 - val_mean_absolute_error: 0.1598\n",
      "Epoch 164/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1373 - mean_absolute_error: 0.1373 - val_loss: 0.1612 - val_mean_absolute_error: 0.1612\n",
      "Epoch 165/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1374 - mean_absolute_error: 0.1374 - val_loss: 0.1595 - val_mean_absolute_error: 0.1595\n",
      "Epoch 166/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1372 - mean_absolute_error: 0.1372 - val_loss: 0.1597 - val_mean_absolute_error: 0.1597\n",
      "Epoch 167/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1374 - mean_absolute_error: 0.1374 - val_loss: 0.1600 - val_mean_absolute_error: 0.1600\n",
      "Epoch 168/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1373 - mean_absolute_error: 0.1373 - val_loss: 0.1604 - val_mean_absolute_error: 0.1604\n",
      "Epoch 169/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1372 - mean_absolute_error: 0.1372 - val_loss: 0.1598 - val_mean_absolute_error: 0.1598\n",
      "Epoch 170/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1372 - mean_absolute_error: 0.1372 - val_loss: 0.1609 - val_mean_absolute_error: 0.1609\n",
      "Epoch 171/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1370 - mean_absolute_error: 0.1370 - val_loss: 0.1602 - val_mean_absolute_error: 0.1602\n",
      "Epoch 172/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1370 - mean_absolute_error: 0.1370 - val_loss: 0.1600 - val_mean_absolute_error: 0.1600\n",
      "Epoch 173/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1369 - mean_absolute_error: 0.1369 - val_loss: 0.1601 - val_mean_absolute_error: 0.1601\n",
      "Epoch 174/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1367 - mean_absolute_error: 0.1367 - val_loss: 0.1601 - val_mean_absolute_error: 0.1601\n",
      "Epoch 175/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1367 - mean_absolute_error: 0.1367 - val_loss: 0.1604 - val_mean_absolute_error: 0.1604\n",
      "Epoch 176/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1367 - mean_absolute_error: 0.1367 - val_loss: 0.1603 - val_mean_absolute_error: 0.1603\n",
      "Epoch 177/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1368 - mean_absolute_error: 0.1368 - val_loss: 0.1597 - val_mean_absolute_error: 0.1597\n",
      "Epoch 178/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1368 - mean_absolute_error: 0.1368 - val_loss: 0.1603 - val_mean_absolute_error: 0.1603\n",
      "Epoch 179/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1365 - mean_absolute_error: 0.1365 - val_loss: 0.1596 - val_mean_absolute_error: 0.1596\n",
      "Epoch 180/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1366 - mean_absolute_error: 0.1366 - val_loss: 0.1625 - val_mean_absolute_error: 0.1625\n",
      "Epoch 181/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1366 - mean_absolute_error: 0.1366 - val_loss: 0.1601 - val_mean_absolute_error: 0.1601\n",
      "Epoch 182/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1365 - mean_absolute_error: 0.1365 - val_loss: 0.1621 - val_mean_absolute_error: 0.1621\n",
      "Epoch 183/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1365 - mean_absolute_error: 0.1365 - val_loss: 0.1606 - val_mean_absolute_error: 0.1606\n",
      "Epoch 184/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1363 - mean_absolute_error: 0.1363 - val_loss: 0.1599 - val_mean_absolute_error: 0.1599\n",
      "Epoch 185/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1363 - mean_absolute_error: 0.1363 - val_loss: 0.1615 - val_mean_absolute_error: 0.1615\n",
      "Epoch 186/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1363 - mean_absolute_error: 0.1363 - val_loss: 0.1595 - val_mean_absolute_error: 0.1595\n",
      "Epoch 187/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1362 - mean_absolute_error: 0.1362 - val_loss: 0.1598 - val_mean_absolute_error: 0.1598\n",
      "Epoch 188/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1359 - mean_absolute_error: 0.1359 - val_loss: 0.1604 - val_mean_absolute_error: 0.1604\n",
      "Epoch 189/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1363 - mean_absolute_error: 0.1363 - val_loss: 0.1604 - val_mean_absolute_error: 0.1604\n",
      "Epoch 190/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1360 - mean_absolute_error: 0.1360 - val_loss: 0.1611 - val_mean_absolute_error: 0.1611\n",
      "Epoch 191/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1362 - mean_absolute_error: 0.1362 - val_loss: 0.1599 - val_mean_absolute_error: 0.1599\n",
      "Epoch 192/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1361 - mean_absolute_error: 0.1361 - val_loss: 0.1597 - val_mean_absolute_error: 0.1597\n",
      "Epoch 193/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1358 - mean_absolute_error: 0.1358 - val_loss: 0.1618 - val_mean_absolute_error: 0.1618\n",
      "Epoch 194/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1359 - mean_absolute_error: 0.1359 - val_loss: 0.1603 - val_mean_absolute_error: 0.1603\n",
      "Epoch 195/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1357 - mean_absolute_error: 0.1357 - val_loss: 0.1599 - val_mean_absolute_error: 0.1599\n",
      "Epoch 196/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1357 - mean_absolute_error: 0.1357 - val_loss: 0.1600 - val_mean_absolute_error: 0.1600\n",
      "Epoch 197/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1357 - mean_absolute_error: 0.1357 - val_loss: 0.1603 - val_mean_absolute_error: 0.1603\n",
      "Epoch 198/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1355 - mean_absolute_error: 0.1355 - val_loss: 0.1606 - val_mean_absolute_error: 0.1606\n",
      "Epoch 199/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1356 - mean_absolute_error: 0.1356 - val_loss: 0.1602 - val_mean_absolute_error: 0.1602\n",
      "Epoch 200/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1356 - mean_absolute_error: 0.1356 - val_loss: 0.1613 - val_mean_absolute_error: 0.1613\n",
      "Epoch 201/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1354 - mean_absolute_error: 0.1354 - val_loss: 0.1644 - val_mean_absolute_error: 0.1644\n",
      "Epoch 202/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1354 - mean_absolute_error: 0.1354 - val_loss: 0.1607 - val_mean_absolute_error: 0.1607\n",
      "Epoch 203/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1356 - mean_absolute_error: 0.1356 - val_loss: 0.1598 - val_mean_absolute_error: 0.1598\n",
      "Epoch 204/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1355 - mean_absolute_error: 0.1355 - val_loss: 0.1603 - val_mean_absolute_error: 0.1603\n",
      "Epoch 205/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1353 - mean_absolute_error: 0.1353 - val_loss: 0.1624 - val_mean_absolute_error: 0.1624\n",
      "Epoch 206/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1351 - mean_absolute_error: 0.1351 - val_loss: 0.1613 - val_mean_absolute_error: 0.1613\n",
      "Epoch 207/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1352 - mean_absolute_error: 0.1352 - val_loss: 0.1604 - val_mean_absolute_error: 0.1604\n",
      "Epoch 208/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1351 - mean_absolute_error: 0.1351 - val_loss: 0.1610 - val_mean_absolute_error: 0.1610\n",
      "Epoch 209/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1352 - mean_absolute_error: 0.1352 - val_loss: 0.1608 - val_mean_absolute_error: 0.1608\n",
      "Epoch 210/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1349 - mean_absolute_error: 0.1349 - val_loss: 0.1619 - val_mean_absolute_error: 0.1619\n",
      "Epoch 211/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1350 - mean_absolute_error: 0.1350 - val_loss: 0.1619 - val_mean_absolute_error: 0.1619\n",
      "Epoch 212/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1350 - mean_absolute_error: 0.1350 - val_loss: 0.1609 - val_mean_absolute_error: 0.1609\n",
      "Epoch 213/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1347 - mean_absolute_error: 0.1347 - val_loss: 0.1606 - val_mean_absolute_error: 0.1606\n",
      "Epoch 214/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1348 - mean_absolute_error: 0.1348 - val_loss: 0.1612 - val_mean_absolute_error: 0.1612\n",
      "Epoch 215/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1347 - mean_absolute_error: 0.1347 - val_loss: 0.1618 - val_mean_absolute_error: 0.1618\n",
      "Epoch 216/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1348 - mean_absolute_error: 0.1348 - val_loss: 0.1650 - val_mean_absolute_error: 0.1650\n",
      "Epoch 217/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1349 - mean_absolute_error: 0.1349 - val_loss: 0.1630 - val_mean_absolute_error: 0.1630\n",
      "Epoch 218/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1347 - mean_absolute_error: 0.1347 - val_loss: 0.1616 - val_mean_absolute_error: 0.1616\n",
      "Epoch 219/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1345 - mean_absolute_error: 0.1345 - val_loss: 0.1605 - val_mean_absolute_error: 0.1605\n",
      "Epoch 220/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1347 - mean_absolute_error: 0.1347 - val_loss: 0.1616 - val_mean_absolute_error: 0.1616\n",
      "Epoch 221/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1344 - mean_absolute_error: 0.1344 - val_loss: 0.1608 - val_mean_absolute_error: 0.1608\n",
      "Epoch 222/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1345 - mean_absolute_error: 0.1345 - val_loss: 0.1611 - val_mean_absolute_error: 0.1611\n",
      "Epoch 223/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1344 - mean_absolute_error: 0.1344 - val_loss: 0.1611 - val_mean_absolute_error: 0.1611\n",
      "Epoch 224/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1343 - mean_absolute_error: 0.1343 - val_loss: 0.1603 - val_mean_absolute_error: 0.1603\n",
      "Epoch 225/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1341 - mean_absolute_error: 0.1341 - val_loss: 0.1624 - val_mean_absolute_error: 0.1624\n",
      "Epoch 226/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1344 - mean_absolute_error: 0.1344 - val_loss: 0.1610 - val_mean_absolute_error: 0.1610\n",
      "Epoch 227/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1341 - mean_absolute_error: 0.1341 - val_loss: 0.1618 - val_mean_absolute_error: 0.1618\n",
      "Epoch 228/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1343 - mean_absolute_error: 0.1343 - val_loss: 0.1623 - val_mean_absolute_error: 0.1623\n",
      "Epoch 229/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1343 - mean_absolute_error: 0.1343 - val_loss: 0.1610 - val_mean_absolute_error: 0.1610\n",
      "Epoch 230/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1342 - mean_absolute_error: 0.1342 - val_loss: 0.1649 - val_mean_absolute_error: 0.1649\n",
      "Epoch 231/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1341 - mean_absolute_error: 0.1341 - val_loss: 0.1618 - val_mean_absolute_error: 0.1618\n",
      "Epoch 232/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1341 - mean_absolute_error: 0.1341 - val_loss: 0.1612 - val_mean_absolute_error: 0.1612\n",
      "Epoch 233/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1340 - mean_absolute_error: 0.1340 - val_loss: 0.1641 - val_mean_absolute_error: 0.1641\n",
      "Epoch 234/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1339 - mean_absolute_error: 0.1339 - val_loss: 0.1613 - val_mean_absolute_error: 0.1613\n",
      "Epoch 235/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1339 - mean_absolute_error: 0.1339 - val_loss: 0.1613 - val_mean_absolute_error: 0.1613\n",
      "Epoch 236/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1340 - mean_absolute_error: 0.1340 - val_loss: 0.1625 - val_mean_absolute_error: 0.1625\n",
      "Epoch 237/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1339 - mean_absolute_error: 0.1339 - val_loss: 0.1609 - val_mean_absolute_error: 0.1609\n",
      "Epoch 238/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1339 - mean_absolute_error: 0.1339 - val_loss: 0.1613 - val_mean_absolute_error: 0.1613\n",
      "Epoch 239/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1337 - mean_absolute_error: 0.1337 - val_loss: 0.1609 - val_mean_absolute_error: 0.1609\n",
      "Epoch 240/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1337 - mean_absolute_error: 0.1337 - val_loss: 0.1652 - val_mean_absolute_error: 0.1652\n",
      "Epoch 241/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1336 - mean_absolute_error: 0.1336 - val_loss: 0.1630 - val_mean_absolute_error: 0.1630\n",
      "Epoch 242/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1336 - mean_absolute_error: 0.1336 - val_loss: 0.1615 - val_mean_absolute_error: 0.1615\n",
      "Epoch 243/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1335 - mean_absolute_error: 0.1335 - val_loss: 0.1619 - val_mean_absolute_error: 0.1619\n",
      "Epoch 244/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1336 - mean_absolute_error: 0.1336 - val_loss: 0.1612 - val_mean_absolute_error: 0.1612\n",
      "Epoch 245/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1334 - mean_absolute_error: 0.1334 - val_loss: 0.1633 - val_mean_absolute_error: 0.1633\n",
      "Epoch 246/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.1612 - val_mean_absolute_error: 0.1612\n",
      "Epoch 247/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1334 - mean_absolute_error: 0.1334 - val_loss: 0.1657 - val_mean_absolute_error: 0.1657\n",
      "Epoch 248/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1335 - mean_absolute_error: 0.1335 - val_loss: 0.1624 - val_mean_absolute_error: 0.1624\n",
      "Epoch 249/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1336 - mean_absolute_error: 0.1336 - val_loss: 0.1613 - val_mean_absolute_error: 0.1613\n",
      "Epoch 250/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1334 - mean_absolute_error: 0.1334 - val_loss: 0.1627 - val_mean_absolute_error: 0.1627\n",
      "Epoch 251/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1334 - mean_absolute_error: 0.1334 - val_loss: 0.1614 - val_mean_absolute_error: 0.1614\n",
      "Epoch 252/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1332 - mean_absolute_error: 0.1332 - val_loss: 0.1613 - val_mean_absolute_error: 0.1613\n",
      "Epoch 253/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.1623 - val_mean_absolute_error: 0.1623\n",
      "Epoch 254/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1331 - mean_absolute_error: 0.1331 - val_loss: 0.1618 - val_mean_absolute_error: 0.1618\n",
      "Epoch 255/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1330 - mean_absolute_error: 0.1330 - val_loss: 0.1620 - val_mean_absolute_error: 0.1620\n",
      "Epoch 256/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1330 - mean_absolute_error: 0.1330 - val_loss: 0.1690 - val_mean_absolute_error: 0.1690\n",
      "Epoch 257/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.1639 - val_mean_absolute_error: 0.1639\n",
      "Epoch 258/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1329 - mean_absolute_error: 0.1329 - val_loss: 0.1620 - val_mean_absolute_error: 0.1620\n",
      "Epoch 259/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1331 - mean_absolute_error: 0.1331 - val_loss: 0.1645 - val_mean_absolute_error: 0.1645\n",
      "Epoch 260/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1330 - mean_absolute_error: 0.1330 - val_loss: 0.1618 - val_mean_absolute_error: 0.1618\n",
      "Epoch 261/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1328 - mean_absolute_error: 0.1328 - val_loss: 0.1618 - val_mean_absolute_error: 0.1618\n",
      "Epoch 262/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1330 - mean_absolute_error: 0.1330 - val_loss: 0.1620 - val_mean_absolute_error: 0.1620\n",
      "Epoch 263/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1329 - mean_absolute_error: 0.1329 - val_loss: 0.1644 - val_mean_absolute_error: 0.1644\n",
      "Epoch 264/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1327 - mean_absolute_error: 0.1327 - val_loss: 0.1622 - val_mean_absolute_error: 0.1622\n",
      "Epoch 265/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1325 - mean_absolute_error: 0.1325 - val_loss: 0.1668 - val_mean_absolute_error: 0.1668\n",
      "Epoch 266/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1329 - mean_absolute_error: 0.1329 - val_loss: 0.1622 - val_mean_absolute_error: 0.1622\n",
      "Epoch 267/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1327 - mean_absolute_error: 0.1327 - val_loss: 0.1616 - val_mean_absolute_error: 0.1616\n",
      "Epoch 268/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1326 - mean_absolute_error: 0.1326 - val_loss: 0.1626 - val_mean_absolute_error: 0.1626\n",
      "Epoch 269/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1326 - mean_absolute_error: 0.1326 - val_loss: 0.1626 - val_mean_absolute_error: 0.1626\n",
      "Epoch 270/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1323 - mean_absolute_error: 0.1323 - val_loss: 0.1659 - val_mean_absolute_error: 0.1659\n",
      "Epoch 271/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1324 - mean_absolute_error: 0.1324 - val_loss: 0.1619 - val_mean_absolute_error: 0.1619\n",
      "Epoch 272/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1323 - mean_absolute_error: 0.1323 - val_loss: 0.1624 - val_mean_absolute_error: 0.1624\n",
      "Epoch 273/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1322 - mean_absolute_error: 0.1322 - val_loss: 0.1628 - val_mean_absolute_error: 0.1628\n",
      "Epoch 274/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1325 - mean_absolute_error: 0.1325 - val_loss: 0.1625 - val_mean_absolute_error: 0.1625\n",
      "Epoch 275/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1323 - mean_absolute_error: 0.1323 - val_loss: 0.1624 - val_mean_absolute_error: 0.1624\n",
      "Epoch 276/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1325 - mean_absolute_error: 0.1325 - val_loss: 0.1631 - val_mean_absolute_error: 0.1631\n",
      "Epoch 277/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1322 - mean_absolute_error: 0.1322 - val_loss: 0.1624 - val_mean_absolute_error: 0.1624\n",
      "Epoch 278/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1323 - mean_absolute_error: 0.1323 - val_loss: 0.1619 - val_mean_absolute_error: 0.1619\n",
      "Epoch 279/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1324 - mean_absolute_error: 0.1324 - val_loss: 0.1649 - val_mean_absolute_error: 0.1649\n",
      "Epoch 280/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1323 - mean_absolute_error: 0.1323 - val_loss: 0.1622 - val_mean_absolute_error: 0.1622\n",
      "Epoch 281/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1322 - mean_absolute_error: 0.1322 - val_loss: 0.1640 - val_mean_absolute_error: 0.1640\n",
      "Epoch 282/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1320 - mean_absolute_error: 0.1320 - val_loss: 0.1640 - val_mean_absolute_error: 0.1640\n",
      "Epoch 283/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1322 - mean_absolute_error: 0.1322 - val_loss: 0.1621 - val_mean_absolute_error: 0.1621\n",
      "Epoch 284/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1320 - mean_absolute_error: 0.1320 - val_loss: 0.1633 - val_mean_absolute_error: 0.1633\n",
      "Epoch 285/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1319 - mean_absolute_error: 0.1319 - val_loss: 0.1625 - val_mean_absolute_error: 0.1625\n",
      "Epoch 286/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1320 - mean_absolute_error: 0.1320 - val_loss: 0.1643 - val_mean_absolute_error: 0.1643\n",
      "Epoch 287/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1319 - mean_absolute_error: 0.1319 - val_loss: 0.1625 - val_mean_absolute_error: 0.1625\n",
      "Epoch 288/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1319 - mean_absolute_error: 0.1319 - val_loss: 0.1625 - val_mean_absolute_error: 0.1625\n",
      "Epoch 289/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1319 - mean_absolute_error: 0.1319 - val_loss: 0.1659 - val_mean_absolute_error: 0.1659\n",
      "Epoch 290/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1319 - mean_absolute_error: 0.1319 - val_loss: 0.1628 - val_mean_absolute_error: 0.1628\n",
      "Epoch 291/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1320 - mean_absolute_error: 0.1320 - val_loss: 0.1626 - val_mean_absolute_error: 0.1626\n",
      "Epoch 292/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1323 - mean_absolute_error: 0.1323 - val_loss: 0.1627 - val_mean_absolute_error: 0.1627\n",
      "Epoch 293/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1318 - mean_absolute_error: 0.1318 - val_loss: 0.1622 - val_mean_absolute_error: 0.1622\n",
      "Epoch 294/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1318 - mean_absolute_error: 0.1318 - val_loss: 0.1621 - val_mean_absolute_error: 0.1621\n",
      "Epoch 295/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1316 - mean_absolute_error: 0.1316 - val_loss: 0.1622 - val_mean_absolute_error: 0.1622\n",
      "Epoch 296/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1316 - mean_absolute_error: 0.1316 - val_loss: 0.1622 - val_mean_absolute_error: 0.1622\n",
      "Epoch 297/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1315 - mean_absolute_error: 0.1315 - val_loss: 0.1623 - val_mean_absolute_error: 0.1623\n",
      "Epoch 298/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1315 - mean_absolute_error: 0.1315 - val_loss: 0.1638 - val_mean_absolute_error: 0.1638\n",
      "Epoch 299/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1315 - mean_absolute_error: 0.1315 - val_loss: 0.1623 - val_mean_absolute_error: 0.1623\n",
      "Epoch 300/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1316 - mean_absolute_error: 0.1316 - val_loss: 0.1630 - val_mean_absolute_error: 0.1630\n",
      "Epoch 301/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1317 - mean_absolute_error: 0.1317 - val_loss: 0.1624 - val_mean_absolute_error: 0.1624\n",
      "Epoch 302/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1314 - mean_absolute_error: 0.1314 - val_loss: 0.1626 - val_mean_absolute_error: 0.1626\n",
      "Epoch 303/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1316 - mean_absolute_error: 0.1316 - val_loss: 0.1630 - val_mean_absolute_error: 0.1630\n",
      "Epoch 304/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1313 - mean_absolute_error: 0.1313 - val_loss: 0.1629 - val_mean_absolute_error: 0.1629\n",
      "Epoch 305/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1313 - mean_absolute_error: 0.1313 - val_loss: 0.1628 - val_mean_absolute_error: 0.1628\n",
      "Epoch 306/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1313 - mean_absolute_error: 0.1313 - val_loss: 0.1627 - val_mean_absolute_error: 0.1627\n",
      "Epoch 307/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1315 - mean_absolute_error: 0.1315 - val_loss: 0.1636 - val_mean_absolute_error: 0.1636\n",
      "Epoch 308/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1311 - mean_absolute_error: 0.1311 - val_loss: 0.1647 - val_mean_absolute_error: 0.1647\n",
      "Epoch 309/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1314 - mean_absolute_error: 0.1314 - val_loss: 0.1637 - val_mean_absolute_error: 0.1637\n",
      "Epoch 310/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1311 - mean_absolute_error: 0.1311 - val_loss: 0.1626 - val_mean_absolute_error: 0.1626\n",
      "Epoch 311/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1310 - mean_absolute_error: 0.1310 - val_loss: 0.1651 - val_mean_absolute_error: 0.1651\n",
      "Epoch 312/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1309 - mean_absolute_error: 0.1309 - val_loss: 0.1623 - val_mean_absolute_error: 0.1623\n",
      "Epoch 313/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1311 - mean_absolute_error: 0.1311 - val_loss: 0.1638 - val_mean_absolute_error: 0.1638\n",
      "Epoch 314/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1310 - mean_absolute_error: 0.1310 - val_loss: 0.1642 - val_mean_absolute_error: 0.1642\n",
      "Epoch 315/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1308 - mean_absolute_error: 0.1308 - val_loss: 0.1634 - val_mean_absolute_error: 0.1634\n",
      "Epoch 316/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1311 - mean_absolute_error: 0.1311 - val_loss: 0.1632 - val_mean_absolute_error: 0.1632\n",
      "Epoch 317/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1309 - mean_absolute_error: 0.1309 - val_loss: 0.1664 - val_mean_absolute_error: 0.1664\n",
      "Epoch 318/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1310 - mean_absolute_error: 0.1310 - val_loss: 0.1637 - val_mean_absolute_error: 0.1637\n",
      "Epoch 319/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1309 - mean_absolute_error: 0.1309 - val_loss: 0.1626 - val_mean_absolute_error: 0.1626\n",
      "Epoch 320/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1308 - mean_absolute_error: 0.1308 - val_loss: 0.1630 - val_mean_absolute_error: 0.1630\n",
      "Epoch 321/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1308 - mean_absolute_error: 0.1308 - val_loss: 0.1663 - val_mean_absolute_error: 0.1663\n",
      "Epoch 322/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1310 - mean_absolute_error: 0.1310 - val_loss: 0.1633 - val_mean_absolute_error: 0.1633\n",
      "Epoch 323/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1308 - mean_absolute_error: 0.1308 - val_loss: 0.1628 - val_mean_absolute_error: 0.1628\n",
      "Epoch 324/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1308 - mean_absolute_error: 0.1308 - val_loss: 0.1629 - val_mean_absolute_error: 0.1629\n",
      "Epoch 325/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1307 - mean_absolute_error: 0.1307 - val_loss: 0.1665 - val_mean_absolute_error: 0.1665\n",
      "Epoch 326/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1307 - mean_absolute_error: 0.1307 - val_loss: 0.1641 - val_mean_absolute_error: 0.1641\n",
      "Epoch 327/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1304 - mean_absolute_error: 0.1304 - val_loss: 0.1626 - val_mean_absolute_error: 0.1626\n",
      "Epoch 328/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1307 - mean_absolute_error: 0.1307 - val_loss: 0.1635 - val_mean_absolute_error: 0.1635\n",
      "Epoch 329/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1308 - mean_absolute_error: 0.1308 - val_loss: 0.1651 - val_mean_absolute_error: 0.1651\n",
      "Epoch 330/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1307 - mean_absolute_error: 0.1307 - val_loss: 0.1658 - val_mean_absolute_error: 0.1658\n",
      "Epoch 331/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1304 - mean_absolute_error: 0.1304 - val_loss: 0.1631 - val_mean_absolute_error: 0.1631\n",
      "Epoch 332/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1306 - mean_absolute_error: 0.1306 - val_loss: 0.1644 - val_mean_absolute_error: 0.1644\n",
      "Epoch 333/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1305 - mean_absolute_error: 0.1305 - val_loss: 0.1657 - val_mean_absolute_error: 0.1657\n",
      "Epoch 334/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1304 - mean_absolute_error: 0.1304 - val_loss: 0.1648 - val_mean_absolute_error: 0.1648\n",
      "Epoch 335/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1305 - mean_absolute_error: 0.1305 - val_loss: 0.1633 - val_mean_absolute_error: 0.1633\n",
      "Epoch 336/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1306 - mean_absolute_error: 0.1306 - val_loss: 0.1637 - val_mean_absolute_error: 0.1637\n",
      "Epoch 337/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1304 - mean_absolute_error: 0.1304 - val_loss: 0.1639 - val_mean_absolute_error: 0.1639\n",
      "Epoch 338/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1303 - mean_absolute_error: 0.1303 - val_loss: 0.1632 - val_mean_absolute_error: 0.1632\n",
      "Epoch 339/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1305 - mean_absolute_error: 0.1305 - val_loss: 0.1630 - val_mean_absolute_error: 0.1630\n",
      "Epoch 340/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1305 - mean_absolute_error: 0.1305 - val_loss: 0.1642 - val_mean_absolute_error: 0.1642\n",
      "Epoch 341/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1303 - mean_absolute_error: 0.1303 - val_loss: 0.1646 - val_mean_absolute_error: 0.1646\n",
      "Epoch 342/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1303 - mean_absolute_error: 0.1303 - val_loss: 0.1631 - val_mean_absolute_error: 0.1631\n",
      "Epoch 343/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1300 - mean_absolute_error: 0.1300 - val_loss: 0.1636 - val_mean_absolute_error: 0.1636\n",
      "Epoch 344/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1304 - mean_absolute_error: 0.1304 - val_loss: 0.1644 - val_mean_absolute_error: 0.1644\n",
      "Epoch 345/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1300 - mean_absolute_error: 0.1300 - val_loss: 0.1633 - val_mean_absolute_error: 0.1633\n",
      "Epoch 346/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1302 - mean_absolute_error: 0.1302 - val_loss: 0.1636 - val_mean_absolute_error: 0.1636\n",
      "Epoch 347/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1301 - mean_absolute_error: 0.1301 - val_loss: 0.1636 - val_mean_absolute_error: 0.1636\n",
      "Epoch 348/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1301 - mean_absolute_error: 0.1301 - val_loss: 0.1642 - val_mean_absolute_error: 0.1642\n",
      "Epoch 349/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1303 - mean_absolute_error: 0.1303 - val_loss: 0.1633 - val_mean_absolute_error: 0.1633\n",
      "Epoch 350/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1301 - mean_absolute_error: 0.1301 - val_loss: 0.1642 - val_mean_absolute_error: 0.1642\n",
      "Epoch 351/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1302 - mean_absolute_error: 0.1302 - val_loss: 0.1630 - val_mean_absolute_error: 0.1630\n",
      "Epoch 352/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1299 - mean_absolute_error: 0.1299 - val_loss: 0.1668 - val_mean_absolute_error: 0.1668\n",
      "Epoch 353/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1301 - mean_absolute_error: 0.1301 - val_loss: 0.1634 - val_mean_absolute_error: 0.1634\n",
      "Epoch 354/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1297 - mean_absolute_error: 0.1297 - val_loss: 0.1632 - val_mean_absolute_error: 0.1632\n",
      "Epoch 355/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1298 - mean_absolute_error: 0.1298 - val_loss: 0.1652 - val_mean_absolute_error: 0.1652\n",
      "Epoch 356/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1300 - mean_absolute_error: 0.1300 - val_loss: 0.1647 - val_mean_absolute_error: 0.1647\n",
      "Epoch 357/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1298 - mean_absolute_error: 0.1298 - val_loss: 0.1665 - val_mean_absolute_error: 0.1665\n",
      "Epoch 358/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1296 - mean_absolute_error: 0.1296 - val_loss: 0.1661 - val_mean_absolute_error: 0.1661\n",
      "Epoch 359/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1298 - mean_absolute_error: 0.1298 - val_loss: 0.1676 - val_mean_absolute_error: 0.1676\n",
      "Epoch 360/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1300 - mean_absolute_error: 0.1300 - val_loss: 0.1637 - val_mean_absolute_error: 0.1637\n",
      "Epoch 361/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1297 - mean_absolute_error: 0.1297 - val_loss: 0.1642 - val_mean_absolute_error: 0.1642\n",
      "Epoch 362/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1296 - mean_absolute_error: 0.1296 - val_loss: 0.1635 - val_mean_absolute_error: 0.1635\n",
      "Epoch 363/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1298 - mean_absolute_error: 0.1298 - val_loss: 0.1676 - val_mean_absolute_error: 0.1676\n",
      "Epoch 364/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1297 - mean_absolute_error: 0.1297 - val_loss: 0.1636 - val_mean_absolute_error: 0.1636\n",
      "Epoch 365/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1294 - mean_absolute_error: 0.1294 - val_loss: 0.1645 - val_mean_absolute_error: 0.1645\n",
      "Epoch 366/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1296 - mean_absolute_error: 0.1296 - val_loss: 0.1635 - val_mean_absolute_error: 0.1635\n",
      "Epoch 367/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1296 - mean_absolute_error: 0.1296 - val_loss: 0.1635 - val_mean_absolute_error: 0.1635\n",
      "Epoch 368/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1296 - mean_absolute_error: 0.1296 - val_loss: 0.1646 - val_mean_absolute_error: 0.1646\n",
      "Epoch 369/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1295 - mean_absolute_error: 0.1295 - val_loss: 0.1645 - val_mean_absolute_error: 0.1645\n",
      "Epoch 370/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1297 - mean_absolute_error: 0.1297 - val_loss: 0.1647 - val_mean_absolute_error: 0.1647\n",
      "Epoch 371/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1296 - mean_absolute_error: 0.1296 - val_loss: 0.1662 - val_mean_absolute_error: 0.1662\n",
      "Epoch 372/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1294 - mean_absolute_error: 0.1294 - val_loss: 0.1637 - val_mean_absolute_error: 0.1637\n",
      "Epoch 373/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1293 - mean_absolute_error: 0.1293 - val_loss: 0.1671 - val_mean_absolute_error: 0.1671\n",
      "Epoch 374/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1293 - mean_absolute_error: 0.1293 - val_loss: 0.1637 - val_mean_absolute_error: 0.1637\n",
      "Epoch 375/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1294 - mean_absolute_error: 0.1294 - val_loss: 0.1646 - val_mean_absolute_error: 0.1646\n",
      "Epoch 376/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1294 - mean_absolute_error: 0.1294 - val_loss: 0.1636 - val_mean_absolute_error: 0.1636\n",
      "Epoch 377/1000\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1293 - mean_absolute_error: 0.1293 - val_loss: 0.1639 - val_mean_absolute_error: 0.1639\n",
      "Epoch 378/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1295 - mean_absolute_error: 0.1295 - val_loss: 0.1646 - val_mean_absolute_error: 0.1646\n",
      "Epoch 379/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1292 - mean_absolute_error: 0.1292 - val_loss: 0.1655 - val_mean_absolute_error: 0.1655\n",
      "Epoch 380/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1291 - mean_absolute_error: 0.1291 - val_loss: 0.1642 - val_mean_absolute_error: 0.1642\n",
      "Epoch 381/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1292 - mean_absolute_error: 0.1292 - val_loss: 0.1634 - val_mean_absolute_error: 0.1634\n",
      "Epoch 382/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1294 - mean_absolute_error: 0.1294 - val_loss: 0.1644 - val_mean_absolute_error: 0.1644\n",
      "Epoch 383/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1292 - mean_absolute_error: 0.1292 - val_loss: 0.1636 - val_mean_absolute_error: 0.1636\n",
      "Epoch 384/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1292 - mean_absolute_error: 0.1292 - val_loss: 0.1651 - val_mean_absolute_error: 0.1651\n",
      "Epoch 385/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1290 - mean_absolute_error: 0.1290 - val_loss: 0.1640 - val_mean_absolute_error: 0.1640\n",
      "Epoch 386/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1291 - mean_absolute_error: 0.1291 - val_loss: 0.1640 - val_mean_absolute_error: 0.1640\n",
      "Epoch 387/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1289 - mean_absolute_error: 0.1289 - val_loss: 0.1642 - val_mean_absolute_error: 0.1642\n",
      "Epoch 388/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1290 - mean_absolute_error: 0.1290 - val_loss: 0.1643 - val_mean_absolute_error: 0.1643\n",
      "Epoch 389/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1291 - mean_absolute_error: 0.1291 - val_loss: 0.1643 - val_mean_absolute_error: 0.1643\n",
      "Epoch 390/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1288 - mean_absolute_error: 0.1288 - val_loss: 0.1636 - val_mean_absolute_error: 0.1636\n",
      "Epoch 391/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1288 - mean_absolute_error: 0.1288 - val_loss: 0.1635 - val_mean_absolute_error: 0.1635\n",
      "Epoch 392/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1288 - mean_absolute_error: 0.1288 - val_loss: 0.1661 - val_mean_absolute_error: 0.1661\n",
      "Epoch 393/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1291 - mean_absolute_error: 0.1291 - val_loss: 0.1641 - val_mean_absolute_error: 0.1641\n",
      "Epoch 394/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1286 - mean_absolute_error: 0.1286 - val_loss: 0.1645 - val_mean_absolute_error: 0.1645\n",
      "Epoch 395/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1288 - mean_absolute_error: 0.1288 - val_loss: 0.1641 - val_mean_absolute_error: 0.1641\n",
      "Epoch 396/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1286 - mean_absolute_error: 0.1286 - val_loss: 0.1654 - val_mean_absolute_error: 0.1654\n",
      "Epoch 397/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1289 - mean_absolute_error: 0.1289 - val_loss: 0.1640 - val_mean_absolute_error: 0.1640\n",
      "Epoch 398/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1286 - mean_absolute_error: 0.1286 - val_loss: 0.1688 - val_mean_absolute_error: 0.1688\n",
      "Epoch 399/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1287 - mean_absolute_error: 0.1287 - val_loss: 0.1667 - val_mean_absolute_error: 0.1667\n",
      "Epoch 400/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1287 - mean_absolute_error: 0.1287 - val_loss: 0.1640 - val_mean_absolute_error: 0.1640\n",
      "Epoch 401/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1288 - mean_absolute_error: 0.1288 - val_loss: 0.1642 - val_mean_absolute_error: 0.1642\n",
      "Epoch 402/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1287 - mean_absolute_error: 0.1287 - val_loss: 0.1644 - val_mean_absolute_error: 0.1644\n",
      "Epoch 403/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1285 - mean_absolute_error: 0.1285 - val_loss: 0.1641 - val_mean_absolute_error: 0.1641\n",
      "Epoch 404/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1285 - mean_absolute_error: 0.1285 - val_loss: 0.1665 - val_mean_absolute_error: 0.1665\n",
      "Epoch 405/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1287 - mean_absolute_error: 0.1287 - val_loss: 0.1640 - val_mean_absolute_error: 0.1640\n",
      "Epoch 406/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1283 - mean_absolute_error: 0.1283 - val_loss: 0.1641 - val_mean_absolute_error: 0.1641\n",
      "Epoch 407/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1283 - mean_absolute_error: 0.1283 - val_loss: 0.1645 - val_mean_absolute_error: 0.1645\n",
      "Epoch 408/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1285 - mean_absolute_error: 0.1285 - val_loss: 0.1654 - val_mean_absolute_error: 0.1654\n",
      "Epoch 409/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1286 - mean_absolute_error: 0.1286 - val_loss: 0.1645 - val_mean_absolute_error: 0.1645\n",
      "Epoch 410/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1286 - mean_absolute_error: 0.1286 - val_loss: 0.1655 - val_mean_absolute_error: 0.1655\n",
      "Epoch 411/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1284 - mean_absolute_error: 0.1284 - val_loss: 0.1643 - val_mean_absolute_error: 0.1643\n",
      "Epoch 412/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1283 - mean_absolute_error: 0.1283 - val_loss: 0.1643 - val_mean_absolute_error: 0.1643\n",
      "Epoch 413/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1284 - mean_absolute_error: 0.1284 - val_loss: 0.1664 - val_mean_absolute_error: 0.1664\n",
      "Epoch 414/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1283 - mean_absolute_error: 0.1283 - val_loss: 0.1644 - val_mean_absolute_error: 0.1644\n",
      "Epoch 415/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1283 - mean_absolute_error: 0.1283 - val_loss: 0.1644 - val_mean_absolute_error: 0.1644\n",
      "Epoch 416/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1281 - mean_absolute_error: 0.1281 - val_loss: 0.1648 - val_mean_absolute_error: 0.1648\n",
      "Epoch 417/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1281 - mean_absolute_error: 0.1281 - val_loss: 0.1644 - val_mean_absolute_error: 0.1644\n",
      "Epoch 418/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1281 - mean_absolute_error: 0.1281 - val_loss: 0.1646 - val_mean_absolute_error: 0.1646\n",
      "Epoch 419/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1282 - mean_absolute_error: 0.1282 - val_loss: 0.1658 - val_mean_absolute_error: 0.1658\n",
      "Epoch 420/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1283 - mean_absolute_error: 0.1283 - val_loss: 0.1643 - val_mean_absolute_error: 0.1643\n",
      "Epoch 421/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1280 - mean_absolute_error: 0.1280 - val_loss: 0.1651 - val_mean_absolute_error: 0.1651\n",
      "Epoch 422/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1281 - mean_absolute_error: 0.1281 - val_loss: 0.1637 - val_mean_absolute_error: 0.1637\n",
      "Epoch 423/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1281 - mean_absolute_error: 0.1281 - val_loss: 0.1682 - val_mean_absolute_error: 0.1682\n",
      "Epoch 424/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1282 - mean_absolute_error: 0.1282 - val_loss: 0.1647 - val_mean_absolute_error: 0.1647\n",
      "Epoch 425/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1280 - mean_absolute_error: 0.1280 - val_loss: 0.1648 - val_mean_absolute_error: 0.1648\n",
      "Epoch 426/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1281 - mean_absolute_error: 0.1281 - val_loss: 0.1650 - val_mean_absolute_error: 0.1650\n",
      "Epoch 427/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1280 - mean_absolute_error: 0.1280 - val_loss: 0.1658 - val_mean_absolute_error: 0.1658\n",
      "Epoch 428/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1277 - mean_absolute_error: 0.1277 - val_loss: 0.1672 - val_mean_absolute_error: 0.1672\n",
      "Epoch 429/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1278 - mean_absolute_error: 0.1278 - val_loss: 0.1642 - val_mean_absolute_error: 0.1642\n",
      "Epoch 430/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1280 - mean_absolute_error: 0.1280 - val_loss: 0.1659 - val_mean_absolute_error: 0.1659\n",
      "Epoch 431/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1279 - mean_absolute_error: 0.1279 - val_loss: 0.1651 - val_mean_absolute_error: 0.1651\n",
      "Epoch 432/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1280 - mean_absolute_error: 0.1280 - val_loss: 0.1647 - val_mean_absolute_error: 0.1647\n",
      "Epoch 433/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1279 - mean_absolute_error: 0.1279 - val_loss: 0.1653 - val_mean_absolute_error: 0.1653\n",
      "Epoch 434/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1277 - mean_absolute_error: 0.1277 - val_loss: 0.1642 - val_mean_absolute_error: 0.1642\n",
      "Epoch 435/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1276 - mean_absolute_error: 0.1276 - val_loss: 0.1635 - val_mean_absolute_error: 0.1635\n",
      "Epoch 436/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1279 - mean_absolute_error: 0.1279 - val_loss: 0.1645 - val_mean_absolute_error: 0.1645\n",
      "Epoch 437/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1277 - mean_absolute_error: 0.1277 - val_loss: 0.1649 - val_mean_absolute_error: 0.1649\n",
      "Epoch 438/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1277 - mean_absolute_error: 0.1277 - val_loss: 0.1644 - val_mean_absolute_error: 0.1644\n",
      "Epoch 439/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1277 - mean_absolute_error: 0.1277 - val_loss: 0.1650 - val_mean_absolute_error: 0.1650\n",
      "Epoch 440/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1275 - mean_absolute_error: 0.1275 - val_loss: 0.1644 - val_mean_absolute_error: 0.1644\n",
      "Epoch 441/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1277 - mean_absolute_error: 0.1277 - val_loss: 0.1664 - val_mean_absolute_error: 0.1664\n",
      "Epoch 442/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1276 - mean_absolute_error: 0.1276 - val_loss: 0.1647 - val_mean_absolute_error: 0.1647\n",
      "Epoch 443/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1274 - mean_absolute_error: 0.1274 - val_loss: 0.1684 - val_mean_absolute_error: 0.1684\n",
      "Epoch 444/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1274 - mean_absolute_error: 0.1274 - val_loss: 0.1665 - val_mean_absolute_error: 0.1665\n",
      "Epoch 445/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1276 - mean_absolute_error: 0.1276 - val_loss: 0.1687 - val_mean_absolute_error: 0.1687\n",
      "Epoch 446/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1275 - mean_absolute_error: 0.1275 - val_loss: 0.1642 - val_mean_absolute_error: 0.1642\n",
      "Epoch 447/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1274 - mean_absolute_error: 0.1274 - val_loss: 0.1645 - val_mean_absolute_error: 0.1645\n",
      "Epoch 448/1000\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1276 - mean_absolute_error: 0.1276 - val_loss: 0.1641 - val_mean_absolute_error: 0.1641\n",
      "Epoch 449/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1272 - mean_absolute_error: 0.1272 - val_loss: 0.1670 - val_mean_absolute_error: 0.1670\n",
      "Epoch 450/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1276 - mean_absolute_error: 0.1276 - val_loss: 0.1647 - val_mean_absolute_error: 0.1647\n",
      "Epoch 451/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1273 - mean_absolute_error: 0.1273 - val_loss: 0.1642 - val_mean_absolute_error: 0.1642\n",
      "Epoch 452/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1276 - mean_absolute_error: 0.1276 - val_loss: 0.1646 - val_mean_absolute_error: 0.1646\n",
      "Epoch 453/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1272 - mean_absolute_error: 0.1272 - val_loss: 0.1640 - val_mean_absolute_error: 0.1640\n",
      "Epoch 454/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1272 - mean_absolute_error: 0.1272 - val_loss: 0.1640 - val_mean_absolute_error: 0.1640\n",
      "Epoch 455/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1274 - mean_absolute_error: 0.1274 - val_loss: 0.1646 - val_mean_absolute_error: 0.1646\n",
      "Epoch 456/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1274 - mean_absolute_error: 0.1274 - val_loss: 0.1651 - val_mean_absolute_error: 0.1651\n",
      "Epoch 457/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1273 - mean_absolute_error: 0.1273 - val_loss: 0.1645 - val_mean_absolute_error: 0.1645\n",
      "Epoch 458/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1272 - mean_absolute_error: 0.1272 - val_loss: 0.1644 - val_mean_absolute_error: 0.1644\n",
      "Epoch 459/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1270 - mean_absolute_error: 0.1270 - val_loss: 0.1646 - val_mean_absolute_error: 0.1646\n",
      "Epoch 460/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1275 - mean_absolute_error: 0.1275 - val_loss: 0.1649 - val_mean_absolute_error: 0.1649\n",
      "Epoch 461/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1271 - mean_absolute_error: 0.1271 - val_loss: 0.1651 - val_mean_absolute_error: 0.1651\n",
      "Epoch 462/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1274 - mean_absolute_error: 0.1274 - val_loss: 0.1646 - val_mean_absolute_error: 0.1646\n",
      "Epoch 463/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1271 - mean_absolute_error: 0.1271 - val_loss: 0.1652 - val_mean_absolute_error: 0.1652\n",
      "Epoch 464/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1270 - mean_absolute_error: 0.1270 - val_loss: 0.1643 - val_mean_absolute_error: 0.1643\n",
      "Epoch 465/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1271 - mean_absolute_error: 0.1271 - val_loss: 0.1642 - val_mean_absolute_error: 0.1642\n",
      "Epoch 466/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1271 - mean_absolute_error: 0.1271 - val_loss: 0.1642 - val_mean_absolute_error: 0.1642\n",
      "Epoch 467/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1272 - mean_absolute_error: 0.1272 - val_loss: 0.1649 - val_mean_absolute_error: 0.1649\n",
      "Epoch 468/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1272 - mean_absolute_error: 0.1272 - val_loss: 0.1655 - val_mean_absolute_error: 0.1655\n",
      "Epoch 469/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1271 - mean_absolute_error: 0.1271 - val_loss: 0.1646 - val_mean_absolute_error: 0.1646\n",
      "Epoch 470/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1271 - mean_absolute_error: 0.1271 - val_loss: 0.1638 - val_mean_absolute_error: 0.1638\n",
      "Epoch 471/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1271 - mean_absolute_error: 0.1271 - val_loss: 0.1640 - val_mean_absolute_error: 0.1640\n",
      "Epoch 472/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1271 - mean_absolute_error: 0.1271 - val_loss: 0.1659 - val_mean_absolute_error: 0.1659\n",
      "Epoch 473/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1271 - mean_absolute_error: 0.1271 - val_loss: 0.1669 - val_mean_absolute_error: 0.1669\n",
      "Epoch 474/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1269 - mean_absolute_error: 0.1269 - val_loss: 0.1639 - val_mean_absolute_error: 0.1639\n",
      "Epoch 475/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1269 - mean_absolute_error: 0.1269 - val_loss: 0.1654 - val_mean_absolute_error: 0.1654\n",
      "Epoch 476/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1271 - mean_absolute_error: 0.1271 - val_loss: 0.1645 - val_mean_absolute_error: 0.1645\n",
      "Epoch 477/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1265 - mean_absolute_error: 0.1265 - val_loss: 0.1652 - val_mean_absolute_error: 0.1652\n",
      "Epoch 478/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1267 - mean_absolute_error: 0.1267 - val_loss: 0.1662 - val_mean_absolute_error: 0.1662\n",
      "Epoch 479/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1267 - mean_absolute_error: 0.1267 - val_loss: 0.1653 - val_mean_absolute_error: 0.1653\n",
      "Epoch 480/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1269 - mean_absolute_error: 0.1269 - val_loss: 0.1645 - val_mean_absolute_error: 0.1645\n",
      "Epoch 481/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1269 - mean_absolute_error: 0.1269 - val_loss: 0.1663 - val_mean_absolute_error: 0.1663\n",
      "Epoch 482/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1270 - mean_absolute_error: 0.1270 - val_loss: 0.1643 - val_mean_absolute_error: 0.1643\n",
      "Epoch 483/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1266 - mean_absolute_error: 0.1266 - val_loss: 0.1667 - val_mean_absolute_error: 0.1667\n",
      "Epoch 484/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1267 - mean_absolute_error: 0.1267 - val_loss: 0.1638 - val_mean_absolute_error: 0.1638\n",
      "Epoch 485/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1267 - mean_absolute_error: 0.1267 - val_loss: 0.1645 - val_mean_absolute_error: 0.1645\n",
      "Epoch 486/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1270 - mean_absolute_error: 0.1270 - val_loss: 0.1652 - val_mean_absolute_error: 0.1652\n",
      "Epoch 487/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1264 - mean_absolute_error: 0.1264 - val_loss: 0.1651 - val_mean_absolute_error: 0.1651\n",
      "Epoch 488/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1266 - mean_absolute_error: 0.1266 - val_loss: 0.1651 - val_mean_absolute_error: 0.1651\n",
      "Epoch 489/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1267 - mean_absolute_error: 0.1267 - val_loss: 0.1643 - val_mean_absolute_error: 0.1643\n",
      "Epoch 490/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1267 - mean_absolute_error: 0.1267 - val_loss: 0.1668 - val_mean_absolute_error: 0.1668\n",
      "Epoch 491/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1266 - mean_absolute_error: 0.1266 - val_loss: 0.1638 - val_mean_absolute_error: 0.1638\n",
      "Epoch 492/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1266 - mean_absolute_error: 0.1266 - val_loss: 0.1656 - val_mean_absolute_error: 0.1656\n",
      "Epoch 493/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1266 - mean_absolute_error: 0.1266 - val_loss: 0.1660 - val_mean_absolute_error: 0.1660\n",
      "Epoch 494/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1268 - mean_absolute_error: 0.1268 - val_loss: 0.1661 - val_mean_absolute_error: 0.1661\n",
      "Epoch 495/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1265 - mean_absolute_error: 0.1265 - val_loss: 0.1668 - val_mean_absolute_error: 0.1668\n",
      "Epoch 496/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1265 - mean_absolute_error: 0.1265 - val_loss: 0.1649 - val_mean_absolute_error: 0.1649\n",
      "Epoch 497/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1265 - mean_absolute_error: 0.1265 - val_loss: 0.1644 - val_mean_absolute_error: 0.1644\n",
      "Epoch 498/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1264 - mean_absolute_error: 0.1264 - val_loss: 0.1668 - val_mean_absolute_error: 0.1668\n",
      "Epoch 499/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1265 - mean_absolute_error: 0.1265 - val_loss: 0.1660 - val_mean_absolute_error: 0.1660\n",
      "Epoch 500/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1265 - mean_absolute_error: 0.1265 - val_loss: 0.1659 - val_mean_absolute_error: 0.1659\n",
      "Epoch 501/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1266 - mean_absolute_error: 0.1266 - val_loss: 0.1651 - val_mean_absolute_error: 0.1651\n",
      "Epoch 502/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1265 - mean_absolute_error: 0.1265 - val_loss: 0.1647 - val_mean_absolute_error: 0.1647\n",
      "Epoch 503/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1265 - mean_absolute_error: 0.1265 - val_loss: 0.1650 - val_mean_absolute_error: 0.1650\n",
      "Epoch 504/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1263 - mean_absolute_error: 0.1263 - val_loss: 0.1648 - val_mean_absolute_error: 0.1648\n",
      "Epoch 505/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1263 - mean_absolute_error: 0.1263 - val_loss: 0.1643 - val_mean_absolute_error: 0.1643\n",
      "Epoch 506/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1262 - mean_absolute_error: 0.1262 - val_loss: 0.1650 - val_mean_absolute_error: 0.1650\n",
      "Epoch 507/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1265 - mean_absolute_error: 0.1265 - val_loss: 0.1668 - val_mean_absolute_error: 0.1668\n",
      "Epoch 508/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1263 - mean_absolute_error: 0.1263 - val_loss: 0.1644 - val_mean_absolute_error: 0.1644\n",
      "Epoch 509/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1264 - mean_absolute_error: 0.1264 - val_loss: 0.1660 - val_mean_absolute_error: 0.1660\n",
      "Epoch 510/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1261 - mean_absolute_error: 0.1261 - val_loss: 0.1663 - val_mean_absolute_error: 0.1663\n",
      "Epoch 511/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1259 - mean_absolute_error: 0.1259 - val_loss: 0.1650 - val_mean_absolute_error: 0.1650\n",
      "Epoch 512/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1263 - mean_absolute_error: 0.1263 - val_loss: 0.1673 - val_mean_absolute_error: 0.1673\n",
      "Epoch 513/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1265 - mean_absolute_error: 0.1265 - val_loss: 0.1661 - val_mean_absolute_error: 0.1661\n",
      "Epoch 514/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1260 - mean_absolute_error: 0.1260 - val_loss: 0.1639 - val_mean_absolute_error: 0.1639\n",
      "Epoch 515/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1264 - mean_absolute_error: 0.1264 - val_loss: 0.1653 - val_mean_absolute_error: 0.1653\n",
      "Epoch 516/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1260 - mean_absolute_error: 0.1260 - val_loss: 0.1654 - val_mean_absolute_error: 0.1654\n",
      "Epoch 517/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1260 - mean_absolute_error: 0.1260 - val_loss: 0.1646 - val_mean_absolute_error: 0.1646\n",
      "Epoch 518/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1263 - mean_absolute_error: 0.1263 - val_loss: 0.1680 - val_mean_absolute_error: 0.1680\n",
      "Epoch 519/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1260 - mean_absolute_error: 0.1260 - val_loss: 0.1653 - val_mean_absolute_error: 0.1653\n",
      "Epoch 520/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1264 - mean_absolute_error: 0.1264 - val_loss: 0.1650 - val_mean_absolute_error: 0.1650\n",
      "Epoch 521/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1259 - mean_absolute_error: 0.1259 - val_loss: 0.1642 - val_mean_absolute_error: 0.1642\n",
      "Epoch 522/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1262 - mean_absolute_error: 0.1262 - val_loss: 0.1675 - val_mean_absolute_error: 0.1675\n",
      "Epoch 523/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1260 - mean_absolute_error: 0.1260 - val_loss: 0.1644 - val_mean_absolute_error: 0.1644\n",
      "Epoch 524/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1262 - mean_absolute_error: 0.1262 - val_loss: 0.1638 - val_mean_absolute_error: 0.1638\n",
      "Epoch 525/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1259 - mean_absolute_error: 0.1259 - val_loss: 0.1647 - val_mean_absolute_error: 0.1647\n",
      "Epoch 526/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1260 - mean_absolute_error: 0.1260 - val_loss: 0.1668 - val_mean_absolute_error: 0.1668\n",
      "Epoch 527/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1256 - mean_absolute_error: 0.1256 - val_loss: 0.1694 - val_mean_absolute_error: 0.1694\n",
      "Epoch 528/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1261 - mean_absolute_error: 0.1261 - val_loss: 0.1654 - val_mean_absolute_error: 0.1654\n",
      "Epoch 529/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1261 - mean_absolute_error: 0.1261 - val_loss: 0.1652 - val_mean_absolute_error: 0.1652\n",
      "Epoch 530/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1261 - mean_absolute_error: 0.1261 - val_loss: 0.1685 - val_mean_absolute_error: 0.1685\n",
      "Epoch 531/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1258 - mean_absolute_error: 0.1258 - val_loss: 0.1647 - val_mean_absolute_error: 0.1647\n",
      "Epoch 532/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1258 - mean_absolute_error: 0.1258 - val_loss: 0.1668 - val_mean_absolute_error: 0.1668\n",
      "Epoch 533/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1259 - mean_absolute_error: 0.1259 - val_loss: 0.1653 - val_mean_absolute_error: 0.1653\n",
      "Epoch 534/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1257 - mean_absolute_error: 0.1257 - val_loss: 0.1656 - val_mean_absolute_error: 0.1656\n",
      "Epoch 535/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1258 - mean_absolute_error: 0.1258 - val_loss: 0.1662 - val_mean_absolute_error: 0.1662\n",
      "Epoch 536/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1257 - mean_absolute_error: 0.1257 - val_loss: 0.1665 - val_mean_absolute_error: 0.1665\n",
      "Epoch 537/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1256 - mean_absolute_error: 0.1256 - val_loss: 0.1644 - val_mean_absolute_error: 0.1644\n",
      "Epoch 538/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1259 - mean_absolute_error: 0.1259 - val_loss: 0.1650 - val_mean_absolute_error: 0.1650\n",
      "Epoch 539/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1258 - mean_absolute_error: 0.1258 - val_loss: 0.1651 - val_mean_absolute_error: 0.1651\n",
      "Epoch 540/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1259 - mean_absolute_error: 0.1259 - val_loss: 0.1651 - val_mean_absolute_error: 0.1651\n",
      "Epoch 541/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1258 - mean_absolute_error: 0.1258 - val_loss: 0.1647 - val_mean_absolute_error: 0.1647\n",
      "Epoch 542/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1256 - mean_absolute_error: 0.1256 - val_loss: 0.1652 - val_mean_absolute_error: 0.1652\n",
      "Epoch 543/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1256 - mean_absolute_error: 0.1256 - val_loss: 0.1647 - val_mean_absolute_error: 0.1647\n",
      "Epoch 544/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1256 - mean_absolute_error: 0.1256 - val_loss: 0.1650 - val_mean_absolute_error: 0.1650\n",
      "Epoch 545/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1254 - mean_absolute_error: 0.1254 - val_loss: 0.1650 - val_mean_absolute_error: 0.1650\n",
      "Epoch 546/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1255 - mean_absolute_error: 0.1255 - val_loss: 0.1671 - val_mean_absolute_error: 0.1671\n",
      "Epoch 547/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1257 - mean_absolute_error: 0.1257 - val_loss: 0.1658 - val_mean_absolute_error: 0.1658\n",
      "Epoch 548/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1255 - mean_absolute_error: 0.1255 - val_loss: 0.1679 - val_mean_absolute_error: 0.1679\n",
      "Epoch 549/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1256 - mean_absolute_error: 0.1256 - val_loss: 0.1719 - val_mean_absolute_error: 0.1719\n",
      "Epoch 550/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1255 - mean_absolute_error: 0.1255 - val_loss: 0.1655 - val_mean_absolute_error: 0.1655\n",
      "Epoch 551/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1253 - mean_absolute_error: 0.1253 - val_loss: 0.1654 - val_mean_absolute_error: 0.1654\n",
      "Epoch 552/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1255 - mean_absolute_error: 0.1255 - val_loss: 0.1696 - val_mean_absolute_error: 0.1696\n",
      "Epoch 553/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1255 - mean_absolute_error: 0.1255 - val_loss: 0.1684 - val_mean_absolute_error: 0.1684\n",
      "Epoch 554/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1253 - mean_absolute_error: 0.1253 - val_loss: 0.1647 - val_mean_absolute_error: 0.1647\n",
      "Epoch 555/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1253 - mean_absolute_error: 0.1253 - val_loss: 0.1654 - val_mean_absolute_error: 0.1654\n",
      "Epoch 556/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1254 - mean_absolute_error: 0.1254 - val_loss: 0.1649 - val_mean_absolute_error: 0.1649\n",
      "Epoch 557/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1253 - mean_absolute_error: 0.1253 - val_loss: 0.1661 - val_mean_absolute_error: 0.1661\n",
      "Epoch 558/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1253 - mean_absolute_error: 0.1253 - val_loss: 0.1655 - val_mean_absolute_error: 0.1655\n",
      "Epoch 559/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1256 - mean_absolute_error: 0.1256 - val_loss: 0.1655 - val_mean_absolute_error: 0.1655\n",
      "Epoch 560/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1255 - mean_absolute_error: 0.1255 - val_loss: 0.1664 - val_mean_absolute_error: 0.1664\n",
      "Epoch 561/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1252 - mean_absolute_error: 0.1252 - val_loss: 0.1657 - val_mean_absolute_error: 0.1657\n",
      "Epoch 562/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1251 - mean_absolute_error: 0.1251 - val_loss: 0.1655 - val_mean_absolute_error: 0.1655\n",
      "Epoch 563/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1253 - mean_absolute_error: 0.1253 - val_loss: 0.1651 - val_mean_absolute_error: 0.1651\n",
      "Epoch 564/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1255 - mean_absolute_error: 0.1255 - val_loss: 0.1676 - val_mean_absolute_error: 0.1676\n",
      "Epoch 565/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1251 - mean_absolute_error: 0.1251 - val_loss: 0.1655 - val_mean_absolute_error: 0.1655\n",
      "Epoch 566/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1251 - mean_absolute_error: 0.1251 - val_loss: 0.1654 - val_mean_absolute_error: 0.1654\n",
      "Epoch 567/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1253 - mean_absolute_error: 0.1253 - val_loss: 0.1654 - val_mean_absolute_error: 0.1654\n",
      "Epoch 568/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1253 - mean_absolute_error: 0.1253 - val_loss: 0.1657 - val_mean_absolute_error: 0.1657\n",
      "Epoch 569/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1250 - mean_absolute_error: 0.1250 - val_loss: 0.1682 - val_mean_absolute_error: 0.1682\n",
      "Epoch 570/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1250 - mean_absolute_error: 0.1250 - val_loss: 0.1662 - val_mean_absolute_error: 0.1662\n",
      "Epoch 571/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1254 - mean_absolute_error: 0.1254 - val_loss: 0.1653 - val_mean_absolute_error: 0.1653\n",
      "Epoch 572/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1251 - mean_absolute_error: 0.1251 - val_loss: 0.1654 - val_mean_absolute_error: 0.1654\n",
      "Epoch 573/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1249 - mean_absolute_error: 0.1249 - val_loss: 0.1654 - val_mean_absolute_error: 0.1654\n",
      "Epoch 574/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1252 - mean_absolute_error: 0.1252 - val_loss: 0.1664 - val_mean_absolute_error: 0.1664\n",
      "Epoch 575/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1252 - mean_absolute_error: 0.1252 - val_loss: 0.1656 - val_mean_absolute_error: 0.1656\n",
      "Epoch 576/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1248 - mean_absolute_error: 0.1248 - val_loss: 0.1675 - val_mean_absolute_error: 0.1675\n",
      "Epoch 577/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1248 - mean_absolute_error: 0.1248 - val_loss: 0.1669 - val_mean_absolute_error: 0.1669\n",
      "Epoch 578/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1250 - mean_absolute_error: 0.1250 - val_loss: 0.1652 - val_mean_absolute_error: 0.1652\n",
      "Epoch 579/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1250 - mean_absolute_error: 0.1250 - val_loss: 0.1673 - val_mean_absolute_error: 0.1673\n",
      "Epoch 580/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1249 - mean_absolute_error: 0.1249 - val_loss: 0.1662 - val_mean_absolute_error: 0.1662\n",
      "Epoch 581/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1249 - mean_absolute_error: 0.1249 - val_loss: 0.1679 - val_mean_absolute_error: 0.1679\n",
      "Epoch 582/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1249 - mean_absolute_error: 0.1249 - val_loss: 0.1654 - val_mean_absolute_error: 0.1654\n",
      "Epoch 583/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1248 - mean_absolute_error: 0.1248 - val_loss: 0.1680 - val_mean_absolute_error: 0.1680\n",
      "Epoch 584/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1252 - mean_absolute_error: 0.1252 - val_loss: 0.1668 - val_mean_absolute_error: 0.1668\n",
      "Epoch 585/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1248 - mean_absolute_error: 0.1248 - val_loss: 0.1652 - val_mean_absolute_error: 0.1652\n",
      "Epoch 586/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1249 - mean_absolute_error: 0.1249 - val_loss: 0.1667 - val_mean_absolute_error: 0.1667\n",
      "Epoch 587/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1250 - mean_absolute_error: 0.1250 - val_loss: 0.1657 - val_mean_absolute_error: 0.1657\n",
      "Epoch 588/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1247 - mean_absolute_error: 0.1247 - val_loss: 0.1665 - val_mean_absolute_error: 0.1665\n",
      "Epoch 589/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1251 - mean_absolute_error: 0.1251 - val_loss: 0.1664 - val_mean_absolute_error: 0.1664\n",
      "Epoch 590/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1248 - mean_absolute_error: 0.1248 - val_loss: 0.1670 - val_mean_absolute_error: 0.1670\n",
      "Epoch 591/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1244 - mean_absolute_error: 0.1244 - val_loss: 0.1681 - val_mean_absolute_error: 0.1681\n",
      "Epoch 592/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1245 - mean_absolute_error: 0.1245 - val_loss: 0.1651 - val_mean_absolute_error: 0.1651\n",
      "Epoch 593/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1247 - mean_absolute_error: 0.1247 - val_loss: 0.1683 - val_mean_absolute_error: 0.1683\n",
      "Epoch 594/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1247 - mean_absolute_error: 0.1247 - val_loss: 0.1667 - val_mean_absolute_error: 0.1667\n",
      "Epoch 595/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1245 - mean_absolute_error: 0.1245 - val_loss: 0.1687 - val_mean_absolute_error: 0.1687\n",
      "Epoch 596/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1249 - mean_absolute_error: 0.1249 - val_loss: 0.1660 - val_mean_absolute_error: 0.1660\n",
      "Epoch 597/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1244 - mean_absolute_error: 0.1244 - val_loss: 0.1658 - val_mean_absolute_error: 0.1658\n",
      "Epoch 598/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1247 - mean_absolute_error: 0.1247 - val_loss: 0.1664 - val_mean_absolute_error: 0.1664\n",
      "Epoch 599/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1247 - mean_absolute_error: 0.1247 - val_loss: 0.1668 - val_mean_absolute_error: 0.1668\n",
      "Epoch 600/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1244 - mean_absolute_error: 0.1244 - val_loss: 0.1665 - val_mean_absolute_error: 0.1665\n",
      "Epoch 601/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1244 - mean_absolute_error: 0.1244 - val_loss: 0.1674 - val_mean_absolute_error: 0.1674\n",
      "Epoch 602/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1245 - mean_absolute_error: 0.1245 - val_loss: 0.1677 - val_mean_absolute_error: 0.1677\n",
      "Epoch 603/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1245 - mean_absolute_error: 0.1245 - val_loss: 0.1658 - val_mean_absolute_error: 0.1658\n",
      "Epoch 604/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1245 - mean_absolute_error: 0.1245 - val_loss: 0.1690 - val_mean_absolute_error: 0.1690\n",
      "Epoch 605/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1244 - mean_absolute_error: 0.1244 - val_loss: 0.1670 - val_mean_absolute_error: 0.1670\n",
      "Epoch 606/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1245 - mean_absolute_error: 0.1245 - val_loss: 0.1664 - val_mean_absolute_error: 0.1664\n",
      "Epoch 607/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1244 - mean_absolute_error: 0.1244 - val_loss: 0.1673 - val_mean_absolute_error: 0.1673\n",
      "Epoch 608/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1242 - mean_absolute_error: 0.1242 - val_loss: 0.1713 - val_mean_absolute_error: 0.1713\n",
      "Epoch 609/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1245 - mean_absolute_error: 0.1245 - val_loss: 0.1678 - val_mean_absolute_error: 0.1678\n",
      "Epoch 610/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1245 - mean_absolute_error: 0.1245 - val_loss: 0.1680 - val_mean_absolute_error: 0.1680\n",
      "Epoch 611/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1245 - mean_absolute_error: 0.1245 - val_loss: 0.1669 - val_mean_absolute_error: 0.1669\n",
      "Epoch 612/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1246 - mean_absolute_error: 0.1246 - val_loss: 0.1677 - val_mean_absolute_error: 0.1677\n",
      "Epoch 613/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1246 - mean_absolute_error: 0.1246 - val_loss: 0.1664 - val_mean_absolute_error: 0.1664\n",
      "Epoch 614/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1242 - mean_absolute_error: 0.1242 - val_loss: 0.1678 - val_mean_absolute_error: 0.1678\n",
      "Epoch 615/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1244 - mean_absolute_error: 0.1244 - val_loss: 0.1686 - val_mean_absolute_error: 0.1686\n",
      "Epoch 616/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1244 - mean_absolute_error: 0.1244 - val_loss: 0.1668 - val_mean_absolute_error: 0.1668\n",
      "Epoch 617/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1242 - mean_absolute_error: 0.1242 - val_loss: 0.1661 - val_mean_absolute_error: 0.1661\n",
      "Epoch 618/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1241 - mean_absolute_error: 0.1241 - val_loss: 0.1674 - val_mean_absolute_error: 0.1674\n",
      "Epoch 619/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1244 - mean_absolute_error: 0.1244 - val_loss: 0.1666 - val_mean_absolute_error: 0.1666\n",
      "Epoch 620/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1244 - mean_absolute_error: 0.1244 - val_loss: 0.1660 - val_mean_absolute_error: 0.1660\n",
      "Epoch 621/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1243 - mean_absolute_error: 0.1243 - val_loss: 0.1664 - val_mean_absolute_error: 0.1664\n",
      "Epoch 622/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1242 - mean_absolute_error: 0.1242 - val_loss: 0.1663 - val_mean_absolute_error: 0.1663\n",
      "Epoch 623/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1238 - mean_absolute_error: 0.1238 - val_loss: 0.1662 - val_mean_absolute_error: 0.1662\n",
      "Epoch 624/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1240 - mean_absolute_error: 0.1240 - val_loss: 0.1690 - val_mean_absolute_error: 0.1690\n",
      "Epoch 625/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1240 - mean_absolute_error: 0.1240 - val_loss: 0.1668 - val_mean_absolute_error: 0.1668\n",
      "Epoch 626/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1241 - mean_absolute_error: 0.1241 - val_loss: 0.1666 - val_mean_absolute_error: 0.1666\n",
      "Epoch 627/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1240 - mean_absolute_error: 0.1240 - val_loss: 0.1677 - val_mean_absolute_error: 0.1677\n",
      "Epoch 628/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1238 - mean_absolute_error: 0.1238 - val_loss: 0.1674 - val_mean_absolute_error: 0.1674\n",
      "Epoch 629/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1241 - mean_absolute_error: 0.1241 - val_loss: 0.1670 - val_mean_absolute_error: 0.1670\n",
      "Epoch 630/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1241 - mean_absolute_error: 0.1241 - val_loss: 0.1677 - val_mean_absolute_error: 0.1677\n",
      "Epoch 631/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1240 - mean_absolute_error: 0.1240 - val_loss: 0.1675 - val_mean_absolute_error: 0.1675\n",
      "Epoch 632/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1238 - mean_absolute_error: 0.1238 - val_loss: 0.1667 - val_mean_absolute_error: 0.1667\n",
      "Epoch 633/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1243 - mean_absolute_error: 0.1243 - val_loss: 0.1677 - val_mean_absolute_error: 0.1677\n",
      "Epoch 634/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1239 - mean_absolute_error: 0.1239 - val_loss: 0.1682 - val_mean_absolute_error: 0.1682\n",
      "Epoch 635/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1237 - mean_absolute_error: 0.1237 - val_loss: 0.1673 - val_mean_absolute_error: 0.1673\n",
      "Epoch 636/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1240 - mean_absolute_error: 0.1240 - val_loss: 0.1670 - val_mean_absolute_error: 0.1670\n",
      "Epoch 637/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1236 - mean_absolute_error: 0.1236 - val_loss: 0.1667 - val_mean_absolute_error: 0.1667\n",
      "Epoch 638/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1238 - mean_absolute_error: 0.1238 - val_loss: 0.1669 - val_mean_absolute_error: 0.1669\n",
      "Epoch 639/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1240 - mean_absolute_error: 0.1240 - val_loss: 0.1675 - val_mean_absolute_error: 0.1675\n",
      "Epoch 640/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1241 - mean_absolute_error: 0.1241 - val_loss: 0.1674 - val_mean_absolute_error: 0.1674\n",
      "Epoch 641/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1238 - mean_absolute_error: 0.1238 - val_loss: 0.1677 - val_mean_absolute_error: 0.1677\n",
      "Epoch 642/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1238 - mean_absolute_error: 0.1238 - val_loss: 0.1681 - val_mean_absolute_error: 0.1681\n",
      "Epoch 643/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1236 - mean_absolute_error: 0.1236 - val_loss: 0.1673 - val_mean_absolute_error: 0.1673\n",
      "Epoch 644/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1239 - mean_absolute_error: 0.1239 - val_loss: 0.1681 - val_mean_absolute_error: 0.1681\n",
      "Epoch 645/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1239 - mean_absolute_error: 0.1239 - val_loss: 0.1671 - val_mean_absolute_error: 0.1671\n",
      "Epoch 646/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1237 - mean_absolute_error: 0.1237 - val_loss: 0.1670 - val_mean_absolute_error: 0.1670\n",
      "Epoch 647/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1238 - mean_absolute_error: 0.1238 - val_loss: 0.1663 - val_mean_absolute_error: 0.1663\n",
      "Epoch 648/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1234 - mean_absolute_error: 0.1234 - val_loss: 0.1666 - val_mean_absolute_error: 0.1666\n",
      "Epoch 649/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1236 - mean_absolute_error: 0.1236 - val_loss: 0.1693 - val_mean_absolute_error: 0.1693\n",
      "Epoch 650/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1235 - mean_absolute_error: 0.1235 - val_loss: 0.1674 - val_mean_absolute_error: 0.1674\n",
      "Epoch 651/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1233 - mean_absolute_error: 0.1233 - val_loss: 0.1674 - val_mean_absolute_error: 0.1674\n",
      "Epoch 652/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1235 - mean_absolute_error: 0.1235 - val_loss: 0.1684 - val_mean_absolute_error: 0.1684\n",
      "Epoch 653/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1236 - mean_absolute_error: 0.1236 - val_loss: 0.1672 - val_mean_absolute_error: 0.1672\n",
      "Epoch 654/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1235 - mean_absolute_error: 0.1235 - val_loss: 0.1677 - val_mean_absolute_error: 0.1677\n",
      "Epoch 655/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1233 - mean_absolute_error: 0.1233 - val_loss: 0.1673 - val_mean_absolute_error: 0.1673\n",
      "Epoch 656/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1233 - mean_absolute_error: 0.1233 - val_loss: 0.1676 - val_mean_absolute_error: 0.1676\n",
      "Epoch 657/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1234 - mean_absolute_error: 0.1234 - val_loss: 0.1677 - val_mean_absolute_error: 0.1677\n",
      "Epoch 658/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1235 - mean_absolute_error: 0.1235 - val_loss: 0.1691 - val_mean_absolute_error: 0.1691\n",
      "Epoch 659/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1233 - mean_absolute_error: 0.1233 - val_loss: 0.1677 - val_mean_absolute_error: 0.1677\n",
      "Epoch 660/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1233 - mean_absolute_error: 0.1233 - val_loss: 0.1671 - val_mean_absolute_error: 0.1671\n",
      "Epoch 661/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1233 - mean_absolute_error: 0.1233 - val_loss: 0.1686 - val_mean_absolute_error: 0.1686\n",
      "Epoch 662/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1234 - mean_absolute_error: 0.1234 - val_loss: 0.1673 - val_mean_absolute_error: 0.1673\n",
      "Epoch 663/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1231 - mean_absolute_error: 0.1231 - val_loss: 0.1676 - val_mean_absolute_error: 0.1676\n",
      "Epoch 664/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1233 - mean_absolute_error: 0.1233 - val_loss: 0.1690 - val_mean_absolute_error: 0.1690\n",
      "Epoch 665/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1235 - mean_absolute_error: 0.1235 - val_loss: 0.1686 - val_mean_absolute_error: 0.1686\n",
      "Epoch 666/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1235 - mean_absolute_error: 0.1235 - val_loss: 0.1673 - val_mean_absolute_error: 0.1673\n",
      "Epoch 667/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1236 - mean_absolute_error: 0.1236 - val_loss: 0.1673 - val_mean_absolute_error: 0.1673\n",
      "Epoch 668/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1231 - mean_absolute_error: 0.1231 - val_loss: 0.1677 - val_mean_absolute_error: 0.1677\n",
      "Epoch 669/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1234 - mean_absolute_error: 0.1234 - val_loss: 0.1676 - val_mean_absolute_error: 0.1676\n",
      "Epoch 670/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1231 - mean_absolute_error: 0.1231 - val_loss: 0.1672 - val_mean_absolute_error: 0.1672\n",
      "Epoch 671/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1232 - mean_absolute_error: 0.1232 - val_loss: 0.1673 - val_mean_absolute_error: 0.1673\n",
      "Epoch 672/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1233 - mean_absolute_error: 0.1233 - val_loss: 0.1676 - val_mean_absolute_error: 0.1676\n",
      "Epoch 673/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1237 - mean_absolute_error: 0.1237 - val_loss: 0.1681 - val_mean_absolute_error: 0.1681\n",
      "Epoch 674/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1234 - mean_absolute_error: 0.1234 - val_loss: 0.1676 - val_mean_absolute_error: 0.1676\n",
      "Epoch 675/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1233 - mean_absolute_error: 0.1233 - val_loss: 0.1686 - val_mean_absolute_error: 0.1686\n",
      "Epoch 676/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1233 - mean_absolute_error: 0.1233 - val_loss: 0.1686 - val_mean_absolute_error: 0.1686\n",
      "Epoch 677/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1234 - mean_absolute_error: 0.1234 - val_loss: 0.1682 - val_mean_absolute_error: 0.1682\n",
      "Epoch 678/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1231 - mean_absolute_error: 0.1231 - val_loss: 0.1690 - val_mean_absolute_error: 0.1690\n",
      "Epoch 679/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1234 - mean_absolute_error: 0.1234 - val_loss: 0.1680 - val_mean_absolute_error: 0.1680\n",
      "Epoch 680/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1229 - mean_absolute_error: 0.1229 - val_loss: 0.1668 - val_mean_absolute_error: 0.1668\n",
      "Epoch 681/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1230 - mean_absolute_error: 0.1230 - val_loss: 0.1673 - val_mean_absolute_error: 0.1673\n",
      "Epoch 682/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1235 - mean_absolute_error: 0.1235 - val_loss: 0.1684 - val_mean_absolute_error: 0.1684\n",
      "Epoch 683/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1233 - mean_absolute_error: 0.1233 - val_loss: 0.1680 - val_mean_absolute_error: 0.1680\n",
      "Epoch 684/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1227 - mean_absolute_error: 0.1227 - val_loss: 0.1683 - val_mean_absolute_error: 0.1683\n",
      "Epoch 685/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1228 - mean_absolute_error: 0.1228 - val_loss: 0.1689 - val_mean_absolute_error: 0.1689\n",
      "Epoch 686/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1231 - mean_absolute_error: 0.1231 - val_loss: 0.1673 - val_mean_absolute_error: 0.1673\n",
      "Epoch 687/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1229 - mean_absolute_error: 0.1229 - val_loss: 0.1682 - val_mean_absolute_error: 0.1682\n",
      "Epoch 688/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1229 - mean_absolute_error: 0.1229 - val_loss: 0.1681 - val_mean_absolute_error: 0.1681\n",
      "Epoch 689/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1227 - mean_absolute_error: 0.1227 - val_loss: 0.1713 - val_mean_absolute_error: 0.1713\n",
      "Epoch 690/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1227 - mean_absolute_error: 0.1227 - val_loss: 0.1684 - val_mean_absolute_error: 0.1684\n",
      "Epoch 691/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1229 - mean_absolute_error: 0.1229 - val_loss: 0.1686 - val_mean_absolute_error: 0.1686\n",
      "Epoch 692/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1229 - mean_absolute_error: 0.1229 - val_loss: 0.1681 - val_mean_absolute_error: 0.1681\n",
      "Epoch 693/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1232 - mean_absolute_error: 0.1232 - val_loss: 0.1680 - val_mean_absolute_error: 0.1680\n",
      "Epoch 694/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1229 - mean_absolute_error: 0.1229 - val_loss: 0.1708 - val_mean_absolute_error: 0.1708\n",
      "Epoch 695/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1232 - mean_absolute_error: 0.1232 - val_loss: 0.1672 - val_mean_absolute_error: 0.1672\n",
      "Epoch 696/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1231 - mean_absolute_error: 0.1231 - val_loss: 0.1719 - val_mean_absolute_error: 0.1719\n",
      "Epoch 697/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1227 - mean_absolute_error: 0.1227 - val_loss: 0.1673 - val_mean_absolute_error: 0.1673\n",
      "Epoch 698/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1228 - mean_absolute_error: 0.1228 - val_loss: 0.1685 - val_mean_absolute_error: 0.1685\n",
      "Epoch 699/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1230 - mean_absolute_error: 0.1230 - val_loss: 0.1674 - val_mean_absolute_error: 0.1674\n",
      "Epoch 700/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1231 - mean_absolute_error: 0.1231 - val_loss: 0.1689 - val_mean_absolute_error: 0.1689\n",
      "Epoch 701/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1234 - mean_absolute_error: 0.1234 - val_loss: 0.1673 - val_mean_absolute_error: 0.1673\n",
      "Epoch 702/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1229 - mean_absolute_error: 0.1229 - val_loss: 0.1670 - val_mean_absolute_error: 0.1670\n",
      "Epoch 703/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1228 - mean_absolute_error: 0.1228 - val_loss: 0.1692 - val_mean_absolute_error: 0.1692\n",
      "Epoch 704/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1227 - mean_absolute_error: 0.1227 - val_loss: 0.1689 - val_mean_absolute_error: 0.1689\n",
      "Epoch 705/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1228 - mean_absolute_error: 0.1228 - val_loss: 0.1676 - val_mean_absolute_error: 0.1676\n",
      "Epoch 706/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1225 - mean_absolute_error: 0.1225 - val_loss: 0.1682 - val_mean_absolute_error: 0.1682\n",
      "Epoch 707/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1228 - mean_absolute_error: 0.1228 - val_loss: 0.1680 - val_mean_absolute_error: 0.1680\n",
      "Epoch 708/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1226 - mean_absolute_error: 0.1226 - val_loss: 0.1686 - val_mean_absolute_error: 0.1686\n",
      "Epoch 709/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1226 - mean_absolute_error: 0.1226 - val_loss: 0.1675 - val_mean_absolute_error: 0.1675\n",
      "Epoch 710/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1228 - mean_absolute_error: 0.1228 - val_loss: 0.1693 - val_mean_absolute_error: 0.1693\n",
      "Epoch 711/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1225 - mean_absolute_error: 0.1225 - val_loss: 0.1675 - val_mean_absolute_error: 0.1675\n",
      "Epoch 712/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1226 - mean_absolute_error: 0.1226 - val_loss: 0.1691 - val_mean_absolute_error: 0.1691\n",
      "Epoch 713/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1230 - mean_absolute_error: 0.1230 - val_loss: 0.1676 - val_mean_absolute_error: 0.1676\n",
      "Epoch 714/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1228 - mean_absolute_error: 0.1228 - val_loss: 0.1668 - val_mean_absolute_error: 0.1668\n",
      "Epoch 715/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1225 - mean_absolute_error: 0.1225 - val_loss: 0.1708 - val_mean_absolute_error: 0.1708\n",
      "Epoch 716/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1228 - mean_absolute_error: 0.1228 - val_loss: 0.1690 - val_mean_absolute_error: 0.1690\n",
      "Epoch 717/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1226 - mean_absolute_error: 0.1226 - val_loss: 0.1675 - val_mean_absolute_error: 0.1675\n",
      "Epoch 718/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1226 - mean_absolute_error: 0.1226 - val_loss: 0.1682 - val_mean_absolute_error: 0.1682\n",
      "Epoch 719/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1226 - mean_absolute_error: 0.1226 - val_loss: 0.1676 - val_mean_absolute_error: 0.1676\n",
      "Epoch 720/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1224 - mean_absolute_error: 0.1224 - val_loss: 0.1695 - val_mean_absolute_error: 0.1695\n",
      "Epoch 721/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1226 - mean_absolute_error: 0.1226 - val_loss: 0.1699 - val_mean_absolute_error: 0.1699\n",
      "Epoch 722/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1228 - mean_absolute_error: 0.1228 - val_loss: 0.1673 - val_mean_absolute_error: 0.1673\n",
      "Epoch 723/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1227 - mean_absolute_error: 0.1227 - val_loss: 0.1678 - val_mean_absolute_error: 0.1678\n",
      "Epoch 724/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1226 - mean_absolute_error: 0.1226 - val_loss: 0.1681 - val_mean_absolute_error: 0.1681\n",
      "Epoch 725/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1223 - mean_absolute_error: 0.1223 - val_loss: 0.1688 - val_mean_absolute_error: 0.1688\n",
      "Epoch 726/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1227 - mean_absolute_error: 0.1227 - val_loss: 0.1678 - val_mean_absolute_error: 0.1678\n",
      "Epoch 727/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1223 - mean_absolute_error: 0.1223 - val_loss: 0.1694 - val_mean_absolute_error: 0.1694\n",
      "Epoch 728/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1224 - mean_absolute_error: 0.1224 - val_loss: 0.1680 - val_mean_absolute_error: 0.1680\n",
      "Epoch 729/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1223 - mean_absolute_error: 0.1223 - val_loss: 0.1678 - val_mean_absolute_error: 0.1678\n",
      "Epoch 730/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1223 - mean_absolute_error: 0.1223 - val_loss: 0.1710 - val_mean_absolute_error: 0.1710\n",
      "Epoch 731/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1224 - mean_absolute_error: 0.1224 - val_loss: 0.1669 - val_mean_absolute_error: 0.1669\n",
      "Epoch 732/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1222 - mean_absolute_error: 0.1222 - val_loss: 0.1693 - val_mean_absolute_error: 0.1693\n",
      "Epoch 733/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1224 - mean_absolute_error: 0.1224 - val_loss: 0.1670 - val_mean_absolute_error: 0.1670\n",
      "Epoch 734/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1223 - mean_absolute_error: 0.1223 - val_loss: 0.1675 - val_mean_absolute_error: 0.1675\n",
      "Epoch 735/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1222 - mean_absolute_error: 0.1222 - val_loss: 0.1693 - val_mean_absolute_error: 0.1693\n",
      "Epoch 736/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1224 - mean_absolute_error: 0.1224 - val_loss: 0.1683 - val_mean_absolute_error: 0.1683\n",
      "Epoch 737/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1222 - mean_absolute_error: 0.1222 - val_loss: 0.1679 - val_mean_absolute_error: 0.1679\n",
      "Epoch 738/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1222 - mean_absolute_error: 0.1222 - val_loss: 0.1706 - val_mean_absolute_error: 0.1706\n",
      "Epoch 739/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1223 - mean_absolute_error: 0.1223 - val_loss: 0.1689 - val_mean_absolute_error: 0.1689\n",
      "Epoch 740/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1222 - mean_absolute_error: 0.1222 - val_loss: 0.1683 - val_mean_absolute_error: 0.1683\n",
      "Epoch 741/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1223 - mean_absolute_error: 0.1223 - val_loss: 0.1693 - val_mean_absolute_error: 0.1693\n",
      "Epoch 742/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1221 - mean_absolute_error: 0.1221 - val_loss: 0.1674 - val_mean_absolute_error: 0.1674\n",
      "Epoch 743/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1223 - mean_absolute_error: 0.1223 - val_loss: 0.1699 - val_mean_absolute_error: 0.1699\n",
      "Epoch 744/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1221 - mean_absolute_error: 0.1221 - val_loss: 0.1680 - val_mean_absolute_error: 0.1680\n",
      "Epoch 745/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1223 - mean_absolute_error: 0.1223 - val_loss: 0.1674 - val_mean_absolute_error: 0.1674\n",
      "Epoch 746/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1222 - mean_absolute_error: 0.1222 - val_loss: 0.1681 - val_mean_absolute_error: 0.1681\n",
      "Epoch 747/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1220 - mean_absolute_error: 0.1220 - val_loss: 0.1698 - val_mean_absolute_error: 0.1698\n",
      "Epoch 748/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1221 - mean_absolute_error: 0.1221 - val_loss: 0.1692 - val_mean_absolute_error: 0.1692\n",
      "Epoch 749/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1221 - mean_absolute_error: 0.1221 - val_loss: 0.1683 - val_mean_absolute_error: 0.1683\n",
      "Epoch 750/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1220 - mean_absolute_error: 0.1220 - val_loss: 0.1707 - val_mean_absolute_error: 0.1707\n",
      "Epoch 751/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1221 - mean_absolute_error: 0.1221 - val_loss: 0.1684 - val_mean_absolute_error: 0.1684\n",
      "Epoch 752/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1221 - mean_absolute_error: 0.1221 - val_loss: 0.1687 - val_mean_absolute_error: 0.1687\n",
      "Epoch 753/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1219 - mean_absolute_error: 0.1219 - val_loss: 0.1683 - val_mean_absolute_error: 0.1683\n",
      "Epoch 754/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1222 - mean_absolute_error: 0.1222 - val_loss: 0.1676 - val_mean_absolute_error: 0.1676\n",
      "Epoch 755/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1220 - mean_absolute_error: 0.1220 - val_loss: 0.1681 - val_mean_absolute_error: 0.1681\n",
      "Epoch 756/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1219 - mean_absolute_error: 0.1219 - val_loss: 0.1682 - val_mean_absolute_error: 0.1682\n",
      "Epoch 757/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1220 - mean_absolute_error: 0.1220 - val_loss: 0.1682 - val_mean_absolute_error: 0.1682\n",
      "Epoch 758/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1219 - mean_absolute_error: 0.1219 - val_loss: 0.1689 - val_mean_absolute_error: 0.1689\n",
      "Epoch 759/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1219 - mean_absolute_error: 0.1219 - val_loss: 0.1702 - val_mean_absolute_error: 0.1702\n",
      "Epoch 760/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1222 - mean_absolute_error: 0.1222 - val_loss: 0.1700 - val_mean_absolute_error: 0.1700\n",
      "Epoch 761/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1222 - mean_absolute_error: 0.1222 - val_loss: 0.1696 - val_mean_absolute_error: 0.1696\n",
      "Epoch 762/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1220 - mean_absolute_error: 0.1220 - val_loss: 0.1676 - val_mean_absolute_error: 0.1676\n",
      "Epoch 763/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1218 - mean_absolute_error: 0.1218 - val_loss: 0.1708 - val_mean_absolute_error: 0.1708\n",
      "Epoch 764/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1217 - mean_absolute_error: 0.1217 - val_loss: 0.1693 - val_mean_absolute_error: 0.1693\n",
      "Epoch 765/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1225 - mean_absolute_error: 0.1225 - val_loss: 0.1679 - val_mean_absolute_error: 0.1679\n",
      "Epoch 766/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1221 - mean_absolute_error: 0.1221 - val_loss: 0.1691 - val_mean_absolute_error: 0.1691\n",
      "Epoch 767/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1220 - mean_absolute_error: 0.1220 - val_loss: 0.1681 - val_mean_absolute_error: 0.1681\n",
      "Epoch 768/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1218 - mean_absolute_error: 0.1218 - val_loss: 0.1692 - val_mean_absolute_error: 0.1692\n",
      "Epoch 769/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1219 - mean_absolute_error: 0.1219 - val_loss: 0.1675 - val_mean_absolute_error: 0.1675\n",
      "Epoch 770/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1217 - mean_absolute_error: 0.1217 - val_loss: 0.1694 - val_mean_absolute_error: 0.1694\n",
      "Epoch 771/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1218 - mean_absolute_error: 0.1218 - val_loss: 0.1687 - val_mean_absolute_error: 0.1687\n",
      "Epoch 772/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1217 - mean_absolute_error: 0.1217 - val_loss: 0.1693 - val_mean_absolute_error: 0.1693\n",
      "Epoch 773/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1218 - mean_absolute_error: 0.1218 - val_loss: 0.1684 - val_mean_absolute_error: 0.1684\n",
      "Epoch 774/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1217 - mean_absolute_error: 0.1217 - val_loss: 0.1694 - val_mean_absolute_error: 0.1694\n",
      "Epoch 775/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1216 - mean_absolute_error: 0.1216 - val_loss: 0.1676 - val_mean_absolute_error: 0.1676\n",
      "Epoch 776/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1221 - mean_absolute_error: 0.1221 - val_loss: 0.1680 - val_mean_absolute_error: 0.1680\n",
      "Epoch 777/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1215 - mean_absolute_error: 0.1215 - val_loss: 0.1674 - val_mean_absolute_error: 0.1674\n",
      "Epoch 778/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1218 - mean_absolute_error: 0.1218 - val_loss: 0.1687 - val_mean_absolute_error: 0.1687\n",
      "Epoch 779/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1217 - mean_absolute_error: 0.1217 - val_loss: 0.1677 - val_mean_absolute_error: 0.1677\n",
      "Epoch 780/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1216 - mean_absolute_error: 0.1216 - val_loss: 0.1680 - val_mean_absolute_error: 0.1680\n",
      "Epoch 781/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1217 - mean_absolute_error: 0.1217 - val_loss: 0.1692 - val_mean_absolute_error: 0.1692\n",
      "Epoch 782/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1219 - mean_absolute_error: 0.1219 - val_loss: 0.1687 - val_mean_absolute_error: 0.1687\n",
      "Epoch 783/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1221 - mean_absolute_error: 0.1221 - val_loss: 0.1712 - val_mean_absolute_error: 0.1712\n",
      "Epoch 784/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1220 - mean_absolute_error: 0.1220 - val_loss: 0.1697 - val_mean_absolute_error: 0.1697\n",
      "Epoch 785/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1216 - mean_absolute_error: 0.1216 - val_loss: 0.1690 - val_mean_absolute_error: 0.1690\n",
      "Epoch 786/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1213 - mean_absolute_error: 0.1213 - val_loss: 0.1682 - val_mean_absolute_error: 0.1682\n",
      "Epoch 787/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1219 - mean_absolute_error: 0.1219 - val_loss: 0.1681 - val_mean_absolute_error: 0.1681\n",
      "Epoch 788/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1214 - mean_absolute_error: 0.1214 - val_loss: 0.1685 - val_mean_absolute_error: 0.1685\n",
      "Epoch 789/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1213 - mean_absolute_error: 0.1213 - val_loss: 0.1688 - val_mean_absolute_error: 0.1688\n",
      "Epoch 790/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1214 - mean_absolute_error: 0.1214 - val_loss: 0.1683 - val_mean_absolute_error: 0.1683\n",
      "Epoch 791/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1215 - mean_absolute_error: 0.1215 - val_loss: 0.1690 - val_mean_absolute_error: 0.1690\n",
      "Epoch 792/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1217 - mean_absolute_error: 0.1217 - val_loss: 0.1680 - val_mean_absolute_error: 0.1680\n",
      "Epoch 793/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1216 - mean_absolute_error: 0.1216 - val_loss: 0.1683 - val_mean_absolute_error: 0.1683\n",
      "Epoch 794/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1217 - mean_absolute_error: 0.1217 - val_loss: 0.1691 - val_mean_absolute_error: 0.1691\n",
      "Epoch 795/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1216 - mean_absolute_error: 0.1216 - val_loss: 0.1684 - val_mean_absolute_error: 0.1684\n",
      "Epoch 796/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1214 - mean_absolute_error: 0.1214 - val_loss: 0.1687 - val_mean_absolute_error: 0.1687\n",
      "Epoch 797/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1215 - mean_absolute_error: 0.1215 - val_loss: 0.1696 - val_mean_absolute_error: 0.1696\n",
      "Epoch 798/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1212 - mean_absolute_error: 0.1212 - val_loss: 0.1688 - val_mean_absolute_error: 0.1688\n",
      "Epoch 799/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1215 - mean_absolute_error: 0.1215 - val_loss: 0.1682 - val_mean_absolute_error: 0.1682\n",
      "Epoch 800/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1210 - mean_absolute_error: 0.1210 - val_loss: 0.1686 - val_mean_absolute_error: 0.1686\n",
      "Epoch 801/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1217 - mean_absolute_error: 0.1217 - val_loss: 0.1692 - val_mean_absolute_error: 0.1692\n",
      "Epoch 802/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1211 - mean_absolute_error: 0.1211 - val_loss: 0.1684 - val_mean_absolute_error: 0.1684\n",
      "Epoch 803/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1211 - mean_absolute_error: 0.1211 - val_loss: 0.1693 - val_mean_absolute_error: 0.1693\n",
      "Epoch 804/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1213 - mean_absolute_error: 0.1213 - val_loss: 0.1696 - val_mean_absolute_error: 0.1696\n",
      "Epoch 805/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1214 - mean_absolute_error: 0.1214 - val_loss: 0.1697 - val_mean_absolute_error: 0.1697\n",
      "Epoch 806/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1213 - mean_absolute_error: 0.1213 - val_loss: 0.1692 - val_mean_absolute_error: 0.1692\n",
      "Epoch 807/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1214 - mean_absolute_error: 0.1214 - val_loss: 0.1690 - val_mean_absolute_error: 0.1690\n",
      "Epoch 808/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1212 - mean_absolute_error: 0.1212 - val_loss: 0.1676 - val_mean_absolute_error: 0.1676\n",
      "Epoch 809/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1212 - mean_absolute_error: 0.1212 - val_loss: 0.1685 - val_mean_absolute_error: 0.1685\n",
      "Epoch 810/1000\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1213 - mean_absolute_error: 0.1213 - val_loss: 0.1690 - val_mean_absolute_error: 0.1690\n",
      "Epoch 811/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1213 - mean_absolute_error: 0.1213 - val_loss: 0.1686 - val_mean_absolute_error: 0.1686\n",
      "Epoch 812/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1214 - mean_absolute_error: 0.1214 - val_loss: 0.1696 - val_mean_absolute_error: 0.1696\n",
      "Epoch 813/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1215 - mean_absolute_error: 0.1215 - val_loss: 0.1687 - val_mean_absolute_error: 0.1687\n",
      "Epoch 814/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1216 - mean_absolute_error: 0.1216 - val_loss: 0.1685 - val_mean_absolute_error: 0.1685\n",
      "Epoch 815/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1213 - mean_absolute_error: 0.1213 - val_loss: 0.1699 - val_mean_absolute_error: 0.1699\n",
      "Epoch 816/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1213 - mean_absolute_error: 0.1213 - val_loss: 0.1710 - val_mean_absolute_error: 0.1710\n",
      "Epoch 817/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1216 - mean_absolute_error: 0.1216 - val_loss: 0.1726 - val_mean_absolute_error: 0.1726\n",
      "Epoch 818/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1212 - mean_absolute_error: 0.1212 - val_loss: 0.1700 - val_mean_absolute_error: 0.1700\n",
      "Epoch 819/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1213 - mean_absolute_error: 0.1213 - val_loss: 0.1740 - val_mean_absolute_error: 0.1740\n",
      "Epoch 820/1000\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1212 - mean_absolute_error: 0.1212 - val_loss: 0.1683 - val_mean_absolute_error: 0.1683\n",
      "Epoch 00820: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "input_dim = xtrain.shape[1]\n",
    "batch_size = int(input_dim/100)\n",
    "with tf.device('/device:GPU:0'):\n",
    "    lr_model_history = dnn.fit(xtrain, ytrain,\n",
    "                        batch_size = batch_size,\n",
    "                        epochs=1000,\n",
    "                        verbose=1,\n",
    "                        validation_data=(xtest, ytest),\n",
    "                        callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "1b5911f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.070\n",
      "MAE: 0.168 \n"
     ]
    }
   ],
   "source": [
    "predictions = dnn.predict(xtest)\n",
    "print(\"R2: {:.3f}\".format(r2_score(ytest, predictions)))\n",
    "print(\"MAE: {:.3f} \".format(mean_absolute_error(ytest, predictions)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830af646",
   "metadata": {},
   "source": [
    "### Predicting valence from the data given \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4daf864",
   "metadata": {},
   "source": [
    "#### Reading the song ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc901c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>uri</th>\n",
       "      <th>track_href</th>\n",
       "      <th>analysis_url</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.436</td>\n",
       "      <td>10</td>\n",
       "      <td>-8.761</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0601</td>\n",
       "      <td>0.72100</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.132</td>\n",
       "      <td>143.874</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>7lPN2DXiMsVn7XUKtOW1CS</td>\n",
       "      <td>spotify:track:7lPN2DXiMsVn7XUKtOW1CS</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/7lPN2DXiMsVn...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/7lPN...</td>\n",
       "      <td>242014</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.680</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.487</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.02120</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.5430</td>\n",
       "      <td>0.644</td>\n",
       "      <td>118.051</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>5QO79kh1waicV47BqGRL3g</td>\n",
       "      <td>spotify:track:5QO79kh1waicV47BqGRL3g</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/5QO79kh1waic...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/5QO7...</td>\n",
       "      <td>215627</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.514</td>\n",
       "      <td>0.730</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.934</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.334</td>\n",
       "      <td>171.005</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>0VjIjW4GlUZAMYd2vXMi3b</td>\n",
       "      <td>spotify:track:0VjIjW4GlUZAMYd2vXMi3b</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/0VjIjW4GlUZA...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/0VjI...</td>\n",
       "      <td>200040</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.731</td>\n",
       "      <td>0.573</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.059</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.40100</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.145</td>\n",
       "      <td>109.928</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>4MzXwWMhyBbmu6hOcLVD49</td>\n",
       "      <td>spotify:track:4MzXwWMhyBbmu6hOcLVD49</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/4MzXwWMhyBbm...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/4MzX...</td>\n",
       "      <td>205090</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.393</td>\n",
       "      <td>4</td>\n",
       "      <td>-7.636</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.45100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.202</td>\n",
       "      <td>104.949</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>5Kskr9LcNYa0tpt5f0ZEJx</td>\n",
       "      <td>spotify:track:5Kskr9LcNYa0tpt5f0ZEJx</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/5Kskr9LcNYa0...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/5Ksk...</td>\n",
       "      <td>205458</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.585   0.436   10    -8.761     1       0.0601       0.72100   \n",
       "0         0.680   0.826    0    -5.487     1       0.0309       0.02120   \n",
       "0         0.514   0.730    1    -5.934     1       0.0598       0.00146   \n",
       "0         0.731   0.573    4   -10.059     0       0.0544       0.40100   \n",
       "0         0.907   0.393    4    -7.636     0       0.0539       0.45100   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo            type  \\\n",
       "0          0.000013    0.1050    0.132  143.874  audio_features   \n",
       "0          0.000012    0.5430    0.644  118.051  audio_features   \n",
       "0          0.000095    0.0897    0.334  171.005  audio_features   \n",
       "0          0.000052    0.1130    0.145  109.928  audio_features   \n",
       "0          0.000001    0.1350    0.202  104.949  audio_features   \n",
       "\n",
       "                       id                                   uri  \\\n",
       "0  7lPN2DXiMsVn7XUKtOW1CS  spotify:track:7lPN2DXiMsVn7XUKtOW1CS   \n",
       "0  5QO79kh1waicV47BqGRL3g  spotify:track:5QO79kh1waicV47BqGRL3g   \n",
       "0  0VjIjW4GlUZAMYd2vXMi3b  spotify:track:0VjIjW4GlUZAMYd2vXMi3b   \n",
       "0  4MzXwWMhyBbmu6hOcLVD49  spotify:track:4MzXwWMhyBbmu6hOcLVD49   \n",
       "0  5Kskr9LcNYa0tpt5f0ZEJx  spotify:track:5Kskr9LcNYa0tpt5f0ZEJx   \n",
       "\n",
       "                                          track_href  \\\n",
       "0  https://api.spotify.com/v1/tracks/7lPN2DXiMsVn...   \n",
       "0  https://api.spotify.com/v1/tracks/5QO79kh1waic...   \n",
       "0  https://api.spotify.com/v1/tracks/0VjIjW4GlUZA...   \n",
       "0  https://api.spotify.com/v1/tracks/4MzXwWMhyBbm...   \n",
       "0  https://api.spotify.com/v1/tracks/5Kskr9LcNYa0...   \n",
       "\n",
       "                                        analysis_url  duration_ms  \\\n",
       "0  https://api.spotify.com/v1/audio-analysis/7lPN...       242014   \n",
       "0  https://api.spotify.com/v1/audio-analysis/5QO7...       215627   \n",
       "0  https://api.spotify.com/v1/audio-analysis/0VjI...       200040   \n",
       "0  https://api.spotify.com/v1/audio-analysis/4MzX...       205090   \n",
       "0  https://api.spotify.com/v1/audio-analysis/5Ksk...       205458   \n",
       "\n",
       "   time_signature  \n",
       "0               4  \n",
       "0               4  \n",
       "0               4  \n",
       "0               4  \n",
       "0               4  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_song = pd.read_csv('spotify_ids.txt', header=None)\n",
    "test_song = test_song.iloc[:,0]\n",
    "test_data = pd.DataFrame()\n",
    "for song in test_song:\n",
    "    test_data = test_data.append(sp.audio_features(song))\n",
    "test_data.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857fabf4",
   "metadata": {},
   "source": [
    "#### Keeping the useful variables and scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "c03492b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['acousticness','danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'instrumentalness', 'liveness', 'tempo', 'duration_ms','time_signature']\n",
    "X, y = test_data[col], test_data['valence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5cbae7",
   "metadata": {},
   "source": [
    "#### Making prredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "96b638de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for neural network: 0.174 \n",
      "MAE for Extra Tree : 0.140 \n"
     ]
    }
   ],
   "source": [
    "predictions = dnn.predict(X)\n",
    "eT_predictions = bestET.predict(X)\n",
    "test_data['pred_valence_nn'] = predictions\n",
    "test_data['pred_valence_et'] = eT_predictions\n",
    "print(\"MAE for neural network: {:.3f} \".format(mean_absolute_error(test_data['valence'], predictions)))\n",
    "print(\"MAE for Extra Tree : {:.3f} \".format(mean_absolute_error(test_data['valence'], rdf_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "002937b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>pred_valence_nn</th>\n",
       "      <th>pred_valence_et</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.132</td>\n",
       "      <td>0.270897</td>\n",
       "      <td>0.132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.644</td>\n",
       "      <td>0.607005</td>\n",
       "      <td>0.624109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.334</td>\n",
       "      <td>0.375980</td>\n",
       "      <td>0.412086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145</td>\n",
       "      <td>0.364640</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.202</td>\n",
       "      <td>0.493048</td>\n",
       "      <td>0.526583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.188</td>\n",
       "      <td>0.329584</td>\n",
       "      <td>0.422451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.768</td>\n",
       "      <td>0.579179</td>\n",
       "      <td>0.486167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.316</td>\n",
       "      <td>0.469767</td>\n",
       "      <td>0.576002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.484</td>\n",
       "      <td>0.452780</td>\n",
       "      <td>0.520245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.180</td>\n",
       "      <td>0.252715</td>\n",
       "      <td>0.254922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1162 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    valence  pred_valence_nn  pred_valence_et\n",
       "0     0.132         0.270897         0.132000\n",
       "0     0.644         0.607005         0.624109\n",
       "0     0.334         0.375980         0.412086\n",
       "0     0.145         0.364640         0.145000\n",
       "0     0.202         0.493048         0.526583\n",
       "..      ...              ...              ...\n",
       "0     0.188         0.329584         0.422451\n",
       "0     0.768         0.579179         0.486167\n",
       "0     0.316         0.469767         0.576002\n",
       "0     0.484         0.452780         0.520245\n",
       "0     0.180         0.252715         0.254922\n",
       "\n",
       "[1162 rows x 3 columns]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[['valence','pred_valence_nn','pred_valence_et']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71da9a63",
   "metadata": {},
   "source": [
    "* Above we can see the mean absolute error for the two methods used "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "263262201a33f9dd073bfbec7f4f442b89dd60e9e8939d41fd86fa46b539bdd1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
